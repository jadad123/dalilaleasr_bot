import requests
import feedparser
import json
import time
import base64
import sqlite3
import os
import re
import urllib.parse
import io
import urllib3
import random
import httpx
from openai import OpenAI
from datetime import datetime
from difflib import SequenceMatcher
from PIL import Image, ImageDraw, ImageFont

# ==========================================
# 0. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… - Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¹ØµØ± V1.0
# ==========================================
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# === Ù†Ø¸Ø§Ù… ØªÙ†Ø§ÙˆØ¨ Ù…ÙØ§ØªÙŠØ­ OpenRouter (6 Ù…ÙØ§ØªÙŠØ­) ===
# ÙŠØªÙ… Ø¥Ø¶Ø§ÙØªÙ‡Ø§ ÙÙŠ Coolify Environment Variables
OPENROUTER_KEYS = [
    os.getenv("OPENROUTER_KEY_1", ""),
    os.getenv("OPENROUTER_KEY_2", ""),
    os.getenv("OPENROUTER_KEY_3", ""),
    os.getenv("OPENROUTER_KEY_4", ""),
    os.getenv("OPENROUTER_KEY_5", ""),
    os.getenv("OPENROUTER_KEY_6", ""),
]
# ØªØµÙÙŠØ© Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„ÙØ§Ø±ØºØ©
OPENROUTER_KEYS = [k for k in OPENROUTER_KEYS if k]

# Ø¹Ø¯Ø§Ø¯ Ù„ØªØªØ¨Ø¹ Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø­Ø§Ù„ÙŠ
current_key_index = 0

def get_next_api_key():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ù†Ø¸Ø§Ù… Round-Robin"""
    global current_key_index
    if not OPENROUTER_KEYS:
        raise ValueError("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù…ÙØ§ØªÙŠØ­ API! ØªØ£ÙƒØ¯ Ù…Ù† Ø¥Ø¶Ø§ÙØªÙ‡Ø§ ÙÙŠ Environment Variables")
    key = OPENROUTER_KEYS[current_key_index]
    current_key_index = (current_key_index + 1) % len(OPENROUTER_KEYS)
    return key

# === Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª WordPress ===
WP_DOMAIN = os.getenv("WP_DOMAIN", "https://dalilaleasr.com")
WP_USER = os.getenv("WP_USER", "admin")
WP_APP_PASS = os.getenv("WP_APP_PASS", "")

WP_ENDPOINT = f"{WP_DOMAIN}/wp-json/wp/v2"

# === Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Bing Image Creator (Ø§Ø®ØªÙŠØ§Ø±ÙŠ - Ù„Ù„Ø¶Ø±ÙˆØ±Ø© ÙÙ‚Ø·) ===
BING_COOKIE = os.getenv("BING_COOKIE", "")

# === Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø§Ø¦ÙŠØ© ===
WATERMARK_TEXT = os.getenv("WATERMARK_TEXT", "dalilaleasr.com")
SITE_NAME = "Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¹ØµØ±"

BROWSER_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8",
    "Referer": "https://google.com"
}

# === Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠØ© ===
FREE_TEXT_MODELS = [
    "google/gemini-2.0-flash-exp:free",
    "meta-llama/llama-3.3-70b-instruct:free",
    "deepseek/deepseek-chat:free",
    "qwen/qwen-2.5-72b-instruct:free",
    "meta-llama/llama-3.1-405b-instruct:free",
    "huggingfaceh4/zephyr-7b-beta:free",
]

FREE_VISION_MODELS = [
    "google/gemini-2.0-flash-exp:free",
    "meta-llama/llama-3.2-90b-vision-instruct:free",
    "meta-llama/llama-3.2-11b-vision-instruct:free",
]

# === Ù†Ù…Ø§Ø°Ø¬ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠØ© (Ù„Ù„Ø¶Ø±ÙˆØ±Ø© ÙÙ‚Ø·) ===
FREE_IMAGE_MODELS = [
    "stabilityai/stable-diffusion-xl-base-1.0",
]

# ==========================================
# 1. Ù…ØµØ§Ø¯Ø± RSS Ø§Ù„Ù…ØªÙ†ÙˆØ¹Ø© - ÙƒÙ„ Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª
# ==========================================
RSS_FEEDS = {
    # === Ø§Ù„ÙƒØ±ÙŠØ¨ØªÙˆ ÙˆØ§Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ© ===
    "crypto": [
        "https://cointelegraph.com/rss",
        "https://decrypt.co/feed",
        "https://cryptoslate.com/feed/",
        "https://bitcoinmagazine.com/.rss/full/",
        "https://blockworks.co/feed/",
        "https://u.today/rss",
        "https://cryptonews.com/news/feed/",
        "https://beincrypto.com/feed/",
        "https://dailyhodl.com/feed/",
        "https://zycrypto.com/feed/",
        "https://www.coindesk.com/arc/outboundfeeds/rss/",
        "https://cryptopotato.com/feed/",
        # Ù…ØµØ§Ø¯Ø± Ø¹Ø±Ø¨ÙŠØ© Ù„Ù„ÙƒØ±ÙŠØ¨ØªÙˆ
        "https://ar.cointelegraph.com/rss",
        "https://arabmarketcap.com/feed/",
    ],
    
    # === Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ§Ù„ØªÙ‚Ù†ÙŠØ© ===
    "ai_tech": [
        "https://techcrunch.com/category/artificial-intelligence/feed/",
        "https://www.wired.com/feed/category/ai/latest/rss",
        "https://venturebeat.com/category/ai/feed/",
        "https://www.theverge.com/rss/ai-artificial-intelligence/index.xml",
        "https://openai.com/blog/rss/",
        "https://blog.google/technology/ai/rss/",
        "https://www.technologyreview.com/feed/",
        "https://news.mit.edu/topic/mitartificial-intelligence2-rss.xml",
        "https://ai.googleblog.com/feeds/posts/default",
        "https://machinelearningmastery.com/feed/",
        # Ù…ØµØ§Ø¯Ø± Ø¹Ø±Ø¨ÙŠØ© Ù„Ù„ØªÙ‚Ù†ÙŠØ©
        "https://aitnews.com/feed/",
        "https://www.tech-wd.com/wd/feed/",
        "https://www.arageek.com/feed",
        "https://www.unlimit-tech.com/feed/",
    ],
    
    # === Ø£Ø®Ø¨Ø§Ø± Ø³ÙŠØ§Ø³ÙŠØ© ÙˆØ§Ù‚ØªØµØ§Ø¯ÙŠØ© ===
    "politics_economy": [
        # Ù…ØµØ§Ø¯Ø± Ø¹Ø±Ø¨ÙŠØ©
        "https://www.aljazeera.net/aljazeerarss/a7c186be-1baa-4bd4-9d80-a84db769f779/73d0e1b4-532f-45ef-b135-bba5a9dd06a3",
        "https://www.alarabiya.net/.mrss/ar.xml",
        "https://www.skynewsarabia.com/web/rss",
        "https://arabic.rt.com/rss/",
        "https://www.france24.com/ar/rss",
        "https://www.bbc.com/arabic/index.xml",
        "https://www.independentarabia.com/rss",
        "https://www.aleqt.com/feed.rss",
        "https://makkahnewspaper.com/rss",
        # Ù…ØµØ§Ø¯Ø± Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
        "https://feeds.bbci.co.uk/news/world/rss.xml",
        "https://rss.nytimes.com/services/xml/rss/nyt/World.xml",
        "https://www.reuters.com/rssFeed/worldNews",
        "https://www.theguardian.com/world/rss",
    ],
    
    # === Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ ÙˆØ§Ù„Ø£Ø¹Ù…Ø§Ù„ ===
    "business": [
        "https://www.cnbc.com/id/100003114/device/rss/rss.html",
        "https://www.bloomberg.com/feed/podcast/etf-iq.xml",
        "https://feeds.a]pnews.com/apnews/Business",
        "https://www.ft.com/rss/home",
        "https://www.economist.com/finance-and-economics/rss.xml",
        # Ø¹Ø±Ø¨ÙŠ
        "https://www.argaam.com/ar/feeds/articles-rss",
        "https://www.mubasher.info/rss/news-sa",
        "https://www.aleqt.com/feed.rss",
        "https://arabic.investing.com/rss/news.rss",
    ],
    
    # === Ø´Ø±ÙˆØ­Ø§Øª ÙˆØªÙ‚Ù†ÙŠØ© Ø§Ù„Ø¨Ø±Ø§Ù…Ø¬ ===
    "tutorials": [
        "https://www.howtogeek.com/feed/",
        "https://lifehacker.com/rss",
        "https://www.makeuseof.com/feed/",
        "https://www.digitaltrends.com/feed/",
        "https://www.tomsguide.com/feeds/all",
        "https://www.pcmag.com/feeds/all-articles",
        "https://www.zdnet.com/rss.xml",
        "https://www.cnet.com/rss/all/",
        # Ø¹Ø±Ø¨ÙŠ
        "https://www.arageek.com/tech/feed",
        "https://www.tech-wd.com/wd/feed/",
        "https://www.unlimit-tech.com/feed/",
        "https://me.kaspersky.com/blog/feed/",
    ],
    
    # === Ø£Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ===
    "security": [
        "https://thehackernews.com/feeds/posts/default",
        "https://www.bleepingcomputer.com/feed/",
        "https://krebsonsecurity.com/feed/",
        "https://www.darkreading.com/rss.xml",
        "https://threatpost.com/feed/",
        "https://securityaffairs.co/wordpress/feed",
    ],
    
    # === Ø§Ù„Ø¹Ù„ÙˆÙ… ÙˆØ§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ ===
    "science": [
        "https://www.sciencedaily.com/rss/all.xml",
        "https://www.nature.com/nature.rss",
        "https://www.newscientist.com/feed/home/",
        "https://www.space.com/feeds/all",
        "https://phys.org/rss-feed/",
        # Ø¹Ø±Ø¨ÙŠ
        "https://www.scientificamerican.com/arabic/rss/",
    ],
}

# === Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø³Ø·Ø­Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ===
ALL_FEEDS = []
for category, feeds in RSS_FEEDS.items():
    ALL_FEEDS.extend(feeds)

# ==========================================
# ==========================================
# 2. Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø£Ù‚Ø³Ø§Ù… (Ù…Ù† Environment Variables)
# ==========================================
# Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© ÙÙŠ Ø­Ø§Ù„ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…ØªØºÙŠØ±
CATEGORY_MAP = {"News": 1, "Uncategorized": 1}
DEFAULT_CATEGORY_ID = 1

# Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…ØªØºÙŠØ± Ù…Ù† Coolify
env_cats_json = os.getenv("CATEGORY_MAP_JSON", "")

if env_cats_json:
    try:
        # ØªØ­ÙˆÙŠÙ„ Ù†Øµ JSON Ø¥Ù„Ù‰ Ù‚Ø§Ù…ÙˆØ³ Ø¨Ø§ÙŠØ«ÙˆÙ†
        loaded_cats = json.loads(env_cats_json)
        CATEGORY_MAP = loaded_cats
        print(f"   âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(CATEGORY_MAP)} Ù‚Ø³Ù… Ù…Ù† Environment Variables.")
    except json.JSONDecodeError as e:
        print(f"   âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© CATEGORY_MAP_JSON: {e}")
        print("   -> ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„ØµÙŠØºØ© JSON ØµØ­ÙŠØ­Ø©ØŒ Ù…Ø«Ø§Ù„: {\"Ø³ÙŠØ§Ø³Ø©\": 46, \"Ø§Ù‚ØªØµØ§Ø¯\": 50}")
else:
    print("   âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ CATEGORY_MAP_JSONØŒ Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ.")

# ==========================================
# 3. Ø®Ø±ÙŠØ·Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
# ==========================================
EMERGENCY_MAP = {
    "bitcoin": [
        "https://images.unsplash.com/photo-1621761191319-c6fb62004040?auto=format&fit=crop&w=1280&q=80",
        "https://images.unsplash.com/photo-1596239464385-2800555f68b4?auto=format&fit=crop&w=1280&q=80",
    ],
    "ethereum": [
        "https://images.unsplash.com/photo-1622630998477-20aa696fab05?auto=format&fit=crop&w=1280&q=80",
    ],
    "ai": [
        "https://images.unsplash.com/photo-1677442136019-21780ecad995?auto=format&fit=crop&w=1280&q=80",
        "https://images.unsplash.com/photo-1684391976641-39e8b13c2a81?auto=format&fit=crop&w=1280&q=80",
        "https://images.unsplash.com/photo-1676299081847-824916de030a?auto=format&fit=crop&w=1280&q=80",
    ],
    "tech": [
        "https://images.unsplash.com/photo-1518770660439-4636190af475?auto=format&fit=crop&w=1280&q=80",
        "https://images.unsplash.com/photo-1488590528505-98d2b5aba04b?auto=format&fit=crop&w=1280&q=80",
    ],
    "security": [
        "https://images.unsplash.com/photo-1563986768609-322da13575f3?auto=format&fit=crop&w=1280&q=80",
        "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?auto=format&fit=crop&w=1280&q=80",
    ],
    "economy": [
        "https://images.unsplash.com/photo-1611974789855-9c2a0a7236a3?auto=format&fit=crop&w=1280&q=80",
        "https://images.unsplash.com/photo-1590283603385-17ffb3a7f29f?auto=format&fit=crop&w=1280&q=80",
    ],
    "politics": [
        "https://images.unsplash.com/photo-1529107386315-e1a2ed48a620?auto=format&fit=crop&w=1280&q=80",
        "https://images.unsplash.com/photo-1555848962-6e79363ec58f?auto=format&fit=crop&w=1280&q=80",
    ],
    "science": [
        "https://images.unsplash.com/photo-1507413245164-6160d8298b31?auto=format&fit=crop&w=1280&q=80",
        "https://images.unsplash.com/photo-1451187580459-43490279c0fa?auto=format&fit=crop&w=1280&q=80",
    ],
    "default": [
        "https://images.unsplash.com/photo-1639762681485-074b7f938ba0?auto=format&fit=crop&w=1280&q=80",
        "https://images.unsplash.com/photo-1620321023374-d1a68fddadb3?auto=format&fit=crop&w=1280&q=80",
    ]
}

DB_FILE = "/app/data/history.db" if os.path.exists("/app/data") else "history.db"

# ==========================================
# 4. Ø¯ÙˆØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ==========================================
def init_db():
    os.makedirs(os.path.dirname(DB_FILE), exist_ok=True) if "/" in DB_FILE else None
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS history 
                 (link TEXT PRIMARY KEY, title TEXT, published_at TEXT)''')
    c.execute('''CREATE TABLE IF NOT EXISTS api_usage 
                 (key_index INTEGER PRIMARY KEY, usage_count INTEGER, last_used TEXT)''')
    conn.commit()
    conn.close()

def is_published_link(link):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("SELECT 1 FROM history WHERE link=?", (link,))
    exists = c.fetchone()
    conn.close()
    return exists is not None

def mark_published(link, title):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("INSERT OR IGNORE INTO history VALUES (?, ?, ?)", 
              (link, title, datetime.now().isoformat()))
    conn.commit()
    conn.close()

# ==========================================
# 5. Ù†Ø¸Ø§Ù… Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø±
# ==========================================
def is_duplicate_semantic(new_title):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("SELECT title FROM history ORDER BY published_at DESC LIMIT 50")
    rows = c.fetchall()
    conn.close()
    if not rows: return False
    
    recent_titles = [row[0] for row in rows if row[0]]
    for existing in recent_titles:
        if SequenceMatcher(None, new_title.lower(), existing.lower()).ratio() > 0.70:
            print(f"   âš ï¸ Ø¹Ù†ÙˆØ§Ù† Ù…ÙƒØ±Ø±: Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ù…Ø¹ '{existing[:30]}...'")
            return True
    return False

# ==========================================
# 6. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
# ==========================================
def check_image_has_watermark(image_url):
    """ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ØµÙˆØ±Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ù„Ø§Ù…Ø© Ù…Ø§Ø¦ÙŠØ©"""
    print(f"   ğŸ” ÙØ­Øµ Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø§Ø¦ÙŠØ©: {image_url[:50]}...")
    
    api_key = get_next_api_key()
    http_client = httpx.Client(verify=False, transport=httpx.HTTPTransport(local_address="0.0.0.0"))
    client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=api_key, http_client=http_client)
    
    for i in range(3):
        model = random.choice(FREE_VISION_MODELS)
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[{
                    "role": "user", 
                    "content": [
                        {
                            "type": "text", 
                            "text": """Analyze this image carefully. Does it contain ANY of the following:
1. Watermarks (text overlay, logo overlay)
2. News channel logos (CNN, BBC, Reuters, etc)
3. Website URLs or domain names
4. Copyright text or symbols
5. Any identifying text overlay

Answer with EXACTLY one of these:
- "CLEAN" if the image has NO watermarks or logos
- "WATERMARK" if the image has ANY watermark, logo, or text overlay"""
                        }, 
                        {"type": "image_url", "image_url": {"url": image_url}}
                    ]
                }],
                max_tokens=50
            )
            result = response.choices[0].message.content.strip().upper()
            print(f"   ğŸ“‹ Ù†ØªÙŠØ¬Ø© Ø§Ù„ÙØ­Øµ: {result}")
            return "WATERMARK" in result
        except Exception as e:
            print(f"   âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙØ­Øµ ({model}): {e}")
            api_key = get_next_api_key()  # Ø¬Ø±Ø¨ Ù…ÙØªØ§Ø­ Ø¢Ø®Ø±
            time.sleep(2)
    
    # ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„ØŒ Ù†ÙØªØ±Ø¶ ÙˆØ¬ÙˆØ¯ Ø¹Ù„Ø§Ù…Ø© Ù…Ø§Ø¦ÙŠØ© Ù„Ù„Ø£Ù…Ø§Ù†
    return True

def apply_watermark_simple(image_bytes):
    """Ø¥Ø¶Ø§ÙØ© Ø¹Ù„Ø§Ù…Ø© Ù…Ø§Ø¦ÙŠØ© Ø¨Ø³ÙŠØ·Ø© Ù„Ù„ØµÙˆØ±Ø© Ø§Ù„Ù†Ø¸ÙŠÙØ©"""
    try:
        img = Image.open(io.BytesIO(image_bytes)).convert("RGBA")
        width, height = img.size
        
        overlay = Image.new("RGBA", img.size, (0, 0, 0, 0))
        draw = ImageDraw.Draw(overlay)
        
        # Ø´Ø±ÙŠØ· Ø´ÙØ§Ù ÙÙŠ Ø§Ù„Ø£Ø³ÙÙ„
        bar_height = int(height * 0.06)
        draw.rectangle([(0, height - bar_height), (width, height)], fill=(0, 0, 0, 140))
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ Ø®Ø· Ø¹Ø±Ø¨ÙŠ Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ
        try:
            font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", int(bar_height * 0.6))
        except:
            try:
                font = ImageFont.truetype("arial.ttf", int(bar_height * 0.6))
            except:
                font = ImageFont.load_default()
        
        # ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø§Ø¦ÙŠØ©
        text = WATERMARK_TEXT
        
        # Ø­Ø³Ø§Ø¨ Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù†Øµ ÙÙŠ Ø§Ù„Ù…Ù†ØªØµÙ
        try:
            bbox = draw.textbbox((0, 0), text, font=font)
            text_width = bbox[2] - bbox[0]
            text_height = bbox[3] - bbox[1]
        except:
            text_width = len(text) * 10
            text_height = bar_height * 0.5
        
        text_x = (width - text_width) / 2
        text_y = height - bar_height + (bar_height - text_height) / 2
        
        # Ø¸Ù„ Ù„Ù„Ù†Øµ
        draw.text((text_x + 2, text_y + 2), text, font=font, fill=(0, 0, 0, 200))
        # Ø§Ù„Ù†Øµ Ø§Ù„Ø£Ø¨ÙŠØ¶
        draw.text((text_x, text_y), text, font=font, fill=(255, 255, 255, 255))
        
        combined = Image.alpha_composite(img, overlay)
        output = io.BytesIO()
        combined.convert("RGB").save(output, format="JPEG", quality=90)
        print(f"   âœ… ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø§Ø¦ÙŠØ©: {WATERMARK_TEXT}")
        return output.getvalue()
        
    except Exception as e:
        print(f"   âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù„Ø§Ù…Ø©: {e}")
        return image_bytes

def apply_watermark_cover(image_bytes):
    """Ø¥Ø®ÙØ§Ø¡ Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø§Ø¦ÙŠØ© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¨Ø´Ø±ÙŠØ· ÙˆÙˆØ¶Ø¹ Ø¹Ù„Ø§Ù…ØªÙ†Ø§ ÙÙˆÙ‚Ù‡"""
    try:
        img = Image.open(io.BytesIO(image_bytes)).convert("RGBA")
        width, height = img.size
        
        overlay = Image.new("RGBA", img.size, (0, 0, 0, 0))
        draw = ImageDraw.Draw(overlay)
        
        # Ø´Ø±ÙŠØ· Ø£ÙƒØ¨Ø± Ù„ØªØºØ·ÙŠØ© Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ù…Ø§Ø¦ÙŠØ© (Ø¹Ø§Ø¯Ø© ÙÙŠ Ø§Ù„Ø£Ø³ÙÙ„ Ø£Ùˆ Ø§Ù„Ø²Ø§ÙˆÙŠØ©)
        bar_height = int(height * 0.12)
        
        # Ø´Ø±ÙŠØ· Ø£Ø³ÙˆØ¯ ØºÙŠØ± Ø´ÙØ§Ù Ù„Ø¥Ø®ÙØ§Ø¡ Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø§Ø¦ÙŠØ© Ø§Ù„Ø£ØµÙ„ÙŠØ©
        draw.rectangle([(0, height - bar_height), (width, height)], fill=(20, 20, 30, 250))
        
        # Ø¥Ø¶Ø§ÙØ© Ø®Ø· Ø²Ø®Ø±ÙÙŠ
        draw.rectangle([(0, height - bar_height), (width, height - bar_height + 3)], fill=(59, 130, 246, 255))
        
        try:
            font_large = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", int(bar_height * 0.5))
            font_small = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", int(bar_height * 0.3))
        except:
            try:
                font_large = ImageFont.truetype("arial.ttf", int(bar_height * 0.5))
                font_small = ImageFont.truetype("arial.ttf", int(bar_height * 0.3))
            except:
                font_large = ImageFont.load_default()
                font_small = font_large
        
        # Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø§Ø¦ÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
        text = WATERMARK_TEXT
        try:
            bbox = draw.textbbox((0, 0), text, font=font_large)
            text_width = bbox[2] - bbox[0]
        except:
            text_width = len(text) * 15
        
        text_x = (width - text_width) / 2
        text_y = height - bar_height + int(bar_height * 0.15)
        
        # Ø¸Ù„ ÙˆÙ†Øµ
        draw.text((text_x + 2, text_y + 2), text, font=font_large, fill=(0, 0, 0, 200))
        draw.text((text_x, text_y), text, font=font_large, fill=(255, 255, 255, 255))
        
        # Ù†Øµ "Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¹ØµØ±" ØªØ­ØªÙ‡
        site_text = SITE_NAME
        try:
            bbox2 = draw.textbbox((0, 0), site_text, font=font_small)
            site_width = bbox2[2] - bbox2[0]
        except:
            site_width = len(site_text) * 8
        
        site_x = (width - site_width) / 2
        site_y = text_y + int(bar_height * 0.45)
        draw.text((site_x, site_y), site_text, font=font_small, fill=(200, 200, 200, 255))
        
        combined = Image.alpha_composite(img, overlay)
        output = io.BytesIO()
        combined.convert("RGB").save(output, format="JPEG", quality=90)
        print(f"   âœ… ØªÙ… Ø¥Ø®ÙØ§Ø¡ Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø§Ø¦ÙŠØ© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© ÙˆÙˆØ¶Ø¹ Ø¹Ù„Ø§Ù…ØªÙ†Ø§: {WATERMARK_TEXT}")
        return output.getvalue()
        
    except Exception as e:
        print(f"   âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØºØ·ÙŠØ© Ø§Ù„Ø¹Ù„Ø§Ù…Ø©: {e}")
        return image_bytes

def get_emergency_image_list(title):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© ØµÙˆØ± Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹"""
    t = title.lower()
    key = "default"
    
    if any(x in t for x in ["bitcoin", "btc", "Ø¨ÙŠØªÙƒÙˆÙŠÙ†"]): key = "bitcoin"
    elif any(x in t for x in ["ethereum", "eth", "Ø¥ÙŠØ«Ø±ÙŠÙˆÙ…"]): key = "ethereum"
    elif any(x in t for x in ["ai", "artificial", "gpt", "Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", "chatgpt"]): key = "ai"
    elif any(x in t for x in ["hack", "security", "Ø£Ù…Ù†", "Ø§Ø®ØªØ±Ø§Ù‚", "cyber"]): key = "security"
    elif any(x in t for x in ["economy", "Ø§Ù‚ØªØµØ§Ø¯", "market", "Ø³ÙˆÙ‚", "stock"]): key = "economy"
    elif any(x in t for x in ["politic", "Ø³ÙŠØ§Ø³", "government", "Ø­ÙƒÙˆÙ…"]): key = "politics"
    elif any(x in t for x in ["science", "Ø¹Ù„Ù…", "space", "ÙØ¶Ø§Ø¡", "research"]): key = "science"
    elif any(x in t for x in ["tech", "ØªÙ‚Ù†", "software", "Ø¨Ø±Ù†Ø§Ù…Ø¬", "app"]): key = "tech"
    
    images = EMERGENCY_MAP.get(key, EMERGENCY_MAP["default"]).copy()
    random.shuffle(images)
    return images

def get_generated_image_url(title):
    """ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ - Ù„Ù„Ø¶Ø±ÙˆØ±Ø© Ø§Ù„Ù‚ØµÙˆÙ‰ ÙÙ‚Ø·"""
    print("   ğŸ¨ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© (Ù„Ù„Ø¶Ø±ÙˆØ±Ø© ÙÙ‚Ø·)...")
    
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Pollinations (Ù…Ø¬Ø§Ù†ÙŠ)
    clean_title = re.sub(r'[^\w\s]', '', title)
    words = clean_title.split()[:6]
    prompt_text = " ".join(words)
    final_prompt = f"{prompt_text}, professional news style, clean, modern, 4k, no text, no watermark"
    encoded_prompt = urllib.parse.quote(final_prompt)
    seed = int(time.time())
    
    return f"https://image.pollinations.ai/prompt/{encoded_prompt}?width=1280&height=720&nologo=true&seed={seed}&model=flux"

# ==========================================
# 7. ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
# ==========================================
def generate_arabic_content(news_item):
    """ØªÙˆÙ„ÙŠØ¯ Ù…Ø­ØªÙˆÙ‰ Ø¹Ø±Ø¨ÙŠ Ø§Ø­ØªØ±Ø§ÙÙŠ Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙˆØ§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª"""
    
    api_key = get_next_api_key()
    print(f"   ğŸ”‘ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙØªØ§Ø­ API: ...{api_key[-8:]}")
    
    http_client = httpx.Client(verify=False, transport=httpx.HTTPTransport(local_address="0.0.0.0"))
    client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=api_key, http_client=http_client)
    
    prompt = f"""Ø£Ù†Øª ÙƒØ§ØªØ¨ Ù…Ø­ØªÙˆÙ‰ Ù…Ø­ØªØ±Ù ÙÙŠ Ù…ÙˆÙ‚Ø¹ "Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¹ØµØ±" - Ù…ÙˆÙ‚Ø¹ Ø¹Ø±Ø¨ÙŠ Ø´Ø§Ù…Ù„ ÙŠØºØ·ÙŠ Ø§Ù„ØªÙ‚Ù†ÙŠØ© ÙˆØ§Ù„Ø§Ù‚ØªØµØ§Ø¯ ÙˆØ§Ù„Ø³ÙŠØ§Ø³Ø©.

Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: Ø§ÙƒØªØ¨ Ù…Ù‚Ø§Ù„Ø§Ù‹ Ø¹Ø±Ø¨ÙŠØ§Ù‹ Ø§Ø­ØªØ±Ø§ÙÙŠØ§Ù‹ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø®Ø¨Ø±:

Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: {news_item['title']}
Ø§Ù„Ù…Ù„Ø®Øµ: {news_item['summary']}

âš ï¸ ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù…Ù‡Ù…Ø© Ø¬Ø¯Ø§Ù‹:
1. Ø§ÙƒØªØ¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø§Ù„Ø³Ù„ÙŠÙ…Ø©
2. Ø§Ø­ØªÙØ¸ Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙˆØ§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙˆØ§Ù„ØªÙˆØ§Ø±ÙŠØ® ÙƒÙ…Ø§ Ù‡ÙŠ Ø¨Ø§Ù„Ø¶Ø¨Ø· - Ù„Ø§ ØªØºÙŠØ± Ø£ÙŠ Ø±Ù‚Ù…
3. Ø§Ø­ØªÙØ¸ Ø¨Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø´Ø®Ø§Øµ ÙˆØ§Ù„Ø´Ø±ÙƒØ§Øª ÙˆØ§Ù„Ù…Ù†Ø¸Ù…Ø§Øª ÙƒÙ…Ø§ Ù‡ÙŠ
4. Ø§Ø­ØªÙØ¸ Ø¨Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ© (Bitcoin, Ethereum, AI, ChatGPT, etc.)
5. Ø§Ù„Ù…Ù‚Ø§Ù„ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø´Ø§Ù…Ù„Ø§Ù‹ ÙˆÙ…ÙØµÙ„Ø§Ù‹ (500-800 ÙƒÙ„Ù…Ø©)

Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:

1. ØµÙ†Ø¯ÙˆÙ‚ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (HTML):
<div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 10px; padding: 20px; margin-bottom: 25px; color: white;">
<h4 style="margin-top: 0; font-size: 1.3em;">ğŸ”¥ Ø£Ø¨Ø±Ø² Ø§Ù„Ù†Ù‚Ø§Ø·</h4>
<ul style="margin: 0; padding-right: 20px;">
<li>Ù†Ù‚Ø·Ø© 1</li>
<li>Ù†Ù‚Ø·Ø© 2</li>
<li>Ù†Ù‚Ø·Ø© 3</li>
</ul>
</div>

2. Ø§Ù„Ù…Ù‚Ø§Ù„: Ø§Ø³ØªØ®Ø¯Ù… <h2> Ù„Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„ÙØ±Ø¹ÙŠØ© Ùˆ <p> Ù„Ù„ÙÙ‚Ø±Ø§Øª

3. ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ù…Ù‚Ø§Ù„ Ø£Ø¶Ù:
META_DESC: ÙˆØµÙ Ù…ÙŠØªØ§ Ù…Ø®ØªØµØ± (150-160 Ø­Ø±Ù)
TAGS: ÙˆØ³ÙˆÙ… Ù…ÙØµÙˆÙ„Ø© Ø¨ÙÙˆØ§ØµÙ„ (5-8 ÙˆØ³ÙˆÙ… Ø¹Ø±Ø¨ÙŠØ© ÙˆØ¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©)
CATEGORY: [Ø§Ø®ØªØ± ÙˆØ§Ø­Ø¯Ø©: Ø£Ø®Ø¨Ø§Ø±, ØªØ­Ù„ÙŠÙ„, Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ, ØªÙ‚Ù†ÙŠØ©, Ø§Ù‚ØªØµØ§Ø¯, Ø³ÙŠØ§Ø³Ø©, Ø´Ø±ÙˆØ­Ø§Øª, Ø£Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª, Ø¹Ù„ÙˆÙ…]
"""
    
    # Ù…Ø­Ø§ÙˆÙ„Ø© 5 Ù…Ø±Ø§Øª Ù…Ø¹ Ù†Ù…Ø§Ø°Ø¬ Ù…Ø®ØªÙ„ÙØ©
    for attempt in range(5):
        model = random.choice(FREE_TEXT_MODELS)
        try:
            print(f"   ğŸ¤– Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}/5 - Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {model}")
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=2000
            )
            content = response.choices[0].message.content
            content = content.replace("```html", "").replace("```", "").strip()
            content = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', content)
            
            print(f"   âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ù†Ø¬Ø§Ø­ ({len(content)} Ø­Ø±Ù)")
            return content
            
        except Exception as e:
            print(f"   âš ï¸ ÙØ´Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ({model}): {e}")
            api_key = get_next_api_key()  # Ø¬Ø±Ø¨ Ù…ÙØªØ§Ø­ Ø¢Ø®Ø±
            client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=api_key, http_client=http_client)
            time.sleep(3)
    
    return None

def generate_arabic_title(original_title):
    """ØªÙˆÙ„ÙŠØ¯ Ø¹Ù†ÙˆØ§Ù† Ø¹Ø±Ø¨ÙŠ Ø¬Ø°Ø§Ø¨"""
    
    api_key = get_next_api_key()
    http_client = httpx.Client(verify=False, transport=httpx.HTTPTransport(local_address="0.0.0.0"))
    client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=api_key, http_client=http_client)
    
    prompt = f"""ØªØ±Ø¬Ù… Ù‡Ø°Ø§ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø´ÙƒÙ„ Ø§Ø­ØªØ±Ø§ÙÙŠ ÙˆØ¬Ø°Ø§Ø¨:

"{original_title}"

Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª:
1. Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙƒÙ…Ø§ Ù‡ÙŠ
2. Ø§Ø­ØªÙØ¸ Ø¨Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¹Ù…Ù„Ø§Øª ÙˆØ§Ù„Ø´Ø±ÙƒØ§Øª Ø§Ù„Ø´Ù‡ÙŠØ±Ø© (Bitcoin, Ethereum, Apple, Google, etc.)
3. Ø§Ø¬Ø¹Ù„ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø¬Ø°Ø§Ø¨Ø§Ù‹ ÙˆÙ…Ù†Ø§Ø³Ø¨Ø§Ù‹ Ù„Ù…ÙˆÙ‚Ø¹ Ø¥Ø®Ø¨Ø§Ø±ÙŠ Ø¹Ø±Ø¨ÙŠ
4. Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 80 Ø­Ø±ÙØ§Ù‹

Ø£Ø¹Ø·Ù†ÙŠ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø¹Ø±Ø¨ÙŠ ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø´Ø±Ø­."""
    
    for attempt in range(3):
        model = random.choice(FREE_TEXT_MODELS)
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=100
            )
            title = response.choices[0].message.content.strip()
            title = title.replace('"', '').replace("'", "").strip()
            if title:
                return title
        except Exception as e:
            print(f"   âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: {e}")
            api_key = get_next_api_key()
            client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=api_key, http_client=http_client)
            time.sleep(2)
    
    return original_title  # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø£ØµÙ„ÙŠ ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„

# ==========================================
# 8. Ø§Ù„Ø±ÙØ¹ ÙˆØ§Ù„Ù†Ø´Ø±
# ==========================================
def get_auth_header():
    clean_pass = WP_APP_PASS.replace(' ', '')
    creds = base64.b64encode(f"{WP_USER}:{clean_pass}".encode()).decode()
    return {"Authorization": f"Basic {creds}", "Content-Type": "application/json"}

def get_or_create_tag_id(tag_name):
    try:
        h = get_auth_header()
        r = requests.get(f"{WP_ENDPOINT}/tags?search={urllib.parse.quote(tag_name)}", headers=h, timeout=10)
        if r.status_code == 200 and r.json(): 
            return r.json()[0]['id']
        r = requests.post(f"{WP_ENDPOINT}/tags", headers=h, json={"name": tag_name}, timeout=10)
        if r.status_code == 201: 
            return r.json()['id']
    except Exception as e:
        print(f"   âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙˆØ³Ù… '{tag_name}': {e}")
    return None

def upload_image_with_seo(img_url, alt_text, has_watermark=False):
    """Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø§Ø¦ÙŠØ©"""
    print(f"   â¬†ï¸ Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±Ø©: {alt_text[:30]}...")
    try:
        r_img = requests.get(img_url, headers=BROWSER_HEADERS, timeout=30, verify=False)
        if r_img.status_code == 200:
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø§Ø¦ÙŠØ©
            if has_watermark:
                final_image_data = apply_watermark_cover(r_img.content)
            else:
                final_image_data = apply_watermark_simple(r_img.content)
            
            filename = f"dalilaleasr_{int(time.time())}.jpg"
            headers_wp = get_auth_header()
            headers_wp["Content-Disposition"] = f"attachment; filename={filename}"
            headers_wp["Content-Type"] = "image/jpeg"
            
            r_wp = requests.post(f"{WP_ENDPOINT}/media", headers=headers_wp, data=final_image_data, timeout=60)
            if r_wp.status_code == 201: 
                media_id = r_wp.json()['id']
                
                # ØªØ­Ø¯ÙŠØ« SEO Ù„Ù„ØµÙˆØ±Ø©
                seo_data = {
                    "alt_text": alt_text, 
                    "title": alt_text, 
                    "caption": f"Ø§Ù„Ù…ØµØ¯Ø±: Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¹ØµØ± - {alt_text}", 
                    "description": alt_text
                }
                requests.post(f"{WP_ENDPOINT}/media/{media_id}", headers=get_auth_header(), json=seo_data, timeout=10)
                print("   âœ… ØªÙ… Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ù†Ø¬Ø§Ø­")
                return media_id
            else:
                print(f"   âŒ ÙØ´Ù„ Ø§Ù„Ø±ÙØ¹: {r_wp.status_code}")
    except Exception as e:
        print(f"   âŒ Ø®Ø·Ø£ ÙÙŠ Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±Ø©: {e}")
    return None

def publish_to_wp(title, content, feat_img_id):
    """Ù†Ø´Ø± Ø§Ù„Ù…Ù‚Ø§Ù„ ÙÙŠ WordPress"""
    meta_desc, tags, cat_id = "", [], DEFAULT_CATEGORY_ID
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØªØ§ ÙˆØ§Ù„ÙˆØ³ÙˆÙ… ÙˆØ§Ù„ØªØµÙ†ÙŠÙ
    if "META_DESC:" in content:
        try:
            parts = content.split("META_DESC:")
            content = parts[0]
            rest = parts[1]
            if "TAGS:" in rest:
                t_parts = rest.split("TAGS:")
                meta_desc = t_parts[0].strip()
                rest = t_parts[1]
                if "CATEGORY:" in rest:
                    c_parts = rest.split("CATEGORY:")
                    tags = [t.strip() for t in c_parts[0].split(',') if t.strip()]
                    
                    for k, v in CATEGORY_MAP.items():
                        if k.lower() in c_parts[1].lower(): 
                            cat_id = v
                            break
        except Exception as e:
            print(f"   âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙŠØªØ§: {e}")
    
    tag_ids = [tid for t in tags if t and (tid := get_or_create_tag_id(t))]
    focus_keyword = tags[0] if tags else "Ø£Ø®Ø¨Ø§Ø±"
    
    data = {
        "title": title, 
        "content": content, 
        "status": "publish",
        "categories": [cat_id], 
        "tags": tag_ids, 
        "excerpt": meta_desc,
        "featured_media": feat_img_id,
        "meta": { 
            "rank_math_focus_keyword": focus_keyword,
            "rank_math_description": meta_desc
        }
    }
    
    try:
        r = requests.post(f"{WP_ENDPOINT}/posts", headers=get_auth_header(), json=data, timeout=30)
        if r.status_code == 201: 
            return r.json()['link']
        print(f"   âŒ ÙØ´Ù„ Ø§Ù„Ù†Ø´Ø±: {r.status_code} - {r.text[:200]}")
    except Exception as e:
        print(f"   âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù†Ø´Ø±: {e}")
    return None

def extract_image_from_entry(entry):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† Ù…Ø¯Ø®Ù„ RSS"""
    # media_content
    if hasattr(entry, 'media_content') and entry.media_content:
        try:
            return entry.media_content[0].get('url') if isinstance(entry.media_content[0], dict) else entry.media_content[0]['url']
        except: pass
    
    # media_thumbnail
    if hasattr(entry, 'media_thumbnail') and entry.media_thumbnail:
        try:
            return entry.media_thumbnail[0].get('url')
        except: pass
    
    # enclosures
    if hasattr(entry, 'enclosures') and entry.enclosures:
        for enc in entry.enclosures:
            if 'image' in enc.get('type', ''):
                return enc.get('href') or enc.get('url')
    
    # links
    if hasattr(entry, 'links') and entry.links:
        for l in entry.links:
            link_type = getattr(l, 'type', '') or l.get('type', '')
            if 'image' in str(link_type): 
                return getattr(l, 'href', None) or l.get('href')
    
    # Ù…Ù† Ø§Ù„Ù…Ù„Ø®Øµ
    if hasattr(entry, 'summary') and entry.summary:
        m = re.search(r'<img.*?src=["\']([^"\']+)["\']', entry.summary)
        if m: return m.group(1)
    
    # Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰
    if hasattr(entry, 'content') and entry.content:
        for c in entry.content:
            content_value = getattr(c, 'value', '') or ''
            m = re.search(r'<img.*?src=["\']([^"\']+)["\']', content_value)
            if m: return m.group(1)
    
    return None

# ==========================================
# 9. Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
# ==========================================
def process_single_entry(entry):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø¨Ø± ÙˆØ§Ø­Ø¯"""
    print(f"\n   âš¡ Ù…Ø¹Ø§Ù„Ø¬Ø©: {entry.title[:60]}...")
    
    # 1. ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©
    arabic_title = generate_arabic_title(entry.title)
    print(f"   ğŸ“ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø¹Ø±Ø¨ÙŠ: {arabic_title[:50]}...")
    
    # 2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† Ø§Ù„Ù…ØµØ¯Ø±
    original_img = extract_image_from_entry(entry)
    final_img_url = None
    has_watermark = False
    
    if original_img:
        print(f"   ğŸ–¼ï¸ ØµÙˆØ±Ø© Ù…Ù† Ø§Ù„Ù…ØµØ¯Ø±: {original_img[:50]}...")
        has_watermark = check_image_has_watermark(original_img)
        final_img_url = original_img
    else:
        # Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙˆØ±Ø© - Ø§Ø³ØªØ®Ø¯Ø§Ù… ØµÙˆØ±Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
        print("   âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙˆØ±Ø© - Ø§Ø³ØªØ®Ø¯Ø§Ù… ØµÙˆØ±Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©...")
        emergency_images = get_emergency_image_list(entry.title)
        if emergency_images:
            final_img_url = emergency_images[0]
            has_watermark = False
    
    # 3. Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±Ø©
    fid = None
    if final_img_url:
        fid = upload_image_with_seo(final_img_url, arabic_title, has_watermark)
    
    # Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„Ø±ÙØ¹ØŒ Ø¬Ø±Ø¨ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
    if not fid:
        print("   ğŸ”„ Ù…Ø­Ø§ÙˆÙ„Ø© ØµÙˆØ± Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©...")
        for backup_url in get_emergency_image_list(entry.title):
            fid = upload_image_with_seo(backup_url, arabic_title, False)
            if fid: break
    
    if not fid:
        print("   âŒ ÙØ´Ù„ Ø±ÙØ¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙˆØ±")
        return False
    
    # 4. ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠ
    summary = getattr(entry, 'summary', '') or getattr(entry, 'description', '')
    content = generate_arabic_content({
        'title': entry.title, 
        'summary': summary
    })
    
    if not content:
        print("   âŒ ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰")
        return False
    
    # 5. Ø§Ù„Ù†Ø´Ø±
    link = publish_to_wp(arabic_title, content, fid)
    if link:
        print(f"   âœ… ØªÙ… Ø§Ù„Ù†Ø´Ø±: {link}")
        mark_published(entry.link, arabic_title)
        return True
    
    return False

def main():
    print("=" * 60)
    print("ğŸš€ Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¹ØµØ± - Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ø´Ø± Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ V1.0")
    print("=" * 60)
    print(f"   ğŸŒ Ø§Ù„Ù…ÙˆÙ‚Ø¹: {WP_DOMAIN}")
    print(f"   ğŸ‘¤ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {WP_USER}")
    print(f"   ğŸ”‘ Ø¹Ø¯Ø¯ Ù…ÙØ§ØªÙŠØ­ API: {len(OPENROUTER_KEYS)}")
    print(f"   ğŸ“° Ø¹Ø¯Ø¯ Ù…ØµØ§Ø¯Ø± RSS: {len(ALL_FEEDS)}")
    print(f"   ğŸ’§ Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø§Ø¦ÙŠØ©: {WATERMARK_TEXT}")
    print("=" * 60)
    
    if not OPENROUTER_KEYS:
        print("âŒ Ø®Ø·Ø£: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙØ§ØªÙŠØ­ API!")
        print("   ØªØ£ÙƒØ¯ Ù…Ù† Ø¥Ø¶Ø§ÙØ© OPENROUTER_KEY_1 Ø¥Ù„Ù‰ OPENROUTER_KEY_6 ÙÙŠ Environment Variables")
        return
    
    init_db()
    
    articles_per_cycle = 0
    max_articles_per_cycle = 10  # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ù…Ù‚Ø§Ù„Ø§Øª ÙÙŠ ÙƒÙ„ Ø¯ÙˆØ±Ø©
    
    while True:
        print(f"\n{'='*60}")
        print(f"â° Ø¯ÙˆØ±Ø© Ø¬Ø¯ÙŠØ¯Ø©: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
        print(f"{'='*60}")
        
        articles_per_cycle = 0
        random.shuffle(ALL_FEEDS)  # Ø®Ù„Ø· Ø§Ù„Ù…ØµØ§Ø¯Ø±
        
        for feed_url in ALL_FEEDS:
            if articles_per_cycle >= max_articles_per_cycle:
                print(f"\n   ğŸ›‘ ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ ({max_articles_per_cycle} Ù…Ù‚Ø§Ù„)")
                break
            
            try:
                print(f"\nğŸ“¡ Ù‚Ø±Ø§Ø¡Ø©: {feed_url[:50]}...")
                d = feedparser.parse(feed_url)
                
                if not d.entries:
                    continue
                
                for entry in d.entries[:3]:  # Ø£ÙˆÙ„ 3 Ø£Ø®Ø¨Ø§Ø± Ù…Ù† ÙƒÙ„ Ù…ØµØ¯Ø±
                    if articles_per_cycle >= max_articles_per_cycle:
                        break
                    
                    # ØªØ®Ø·ÙŠ Ø§Ù„Ù…Ù†Ø´ÙˆØ± Ø³Ø§Ø¨Ù‚Ø§Ù‹
                    if is_published_link(entry.link):
                        continue
                    
                    # ØªØ®Ø·ÙŠ Ø§Ù„Ù…ÙƒØ±Ø± Ø¯Ù„Ø§Ù„ÙŠØ§Ù‹
                    if is_duplicate_semantic(entry.title):
                        continue
                    
                    # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆÙ†Ø´Ø±
                    if process_single_entry(entry):
                        articles_per_cycle += 1
                    
                    # Ø§Ù†ØªØ¸Ø§Ø± Ø¨ÙŠÙ† Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª
                    time.sleep(20)
                    
            except Exception as e:
                print(f"   âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…ØµØ¯Ø±: {e}")
                continue
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„Ø¯ÙˆØ±Ø©: ØªÙ… Ù†Ø´Ø± {articles_per_cycle} Ù…Ù‚Ø§Ù„")
        print(f"ğŸ’¤ Ø§Ø³ØªØ±Ø§Ø­Ø© 20 Ø¯Ù‚ÙŠÙ‚Ø©...")
        print(f"{'='*60}")
        
        time.sleep(1200)  # 20 Ø¯Ù‚ÙŠÙ‚Ø©

if __name__ == "__main__":
    main()

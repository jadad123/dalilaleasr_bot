import requests
import feedparser
import json
import time
import base64
import sqlite3
import os
import re
import urllib.parse
import io
import urllib3
import random
import httpx
from openai import OpenAI
from datetime import datetime
from difflib import SequenceMatcher
import difflib
from PIL import Image, ImageDraw, ImageFont

# ==========================================
# 0. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… - Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¹ØµØ± V1.0
# ==========================================
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# === Ù†Ø¸Ø§Ù… ØªÙ†Ø§ÙˆØ¨ Ù…ÙØ§ØªÙŠØ­ OpenRouter (6 Ù…ÙØ§ØªÙŠØ­) ===
# ÙŠØªÙ… Ø¥Ø¶Ø§ÙØªÙ‡Ø§ ÙÙŠ Coolify Environment Variables
OPENROUTER_KEYS = [
    os.getenv("OPENROUTER_KEY_1", ""),
    os.getenv("OPENROUTER_KEY_2", ""),
    os.getenv("OPENROUTER_KEY_3", ""),
    os.getenv("OPENROUTER_KEY_4", ""),
    os.getenv("OPENROUTER_KEY_5", ""),
    os.getenv("OPENROUTER_KEY_6", ""),
]
# ØªØµÙÙŠØ© Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„ÙØ§Ø±ØºØ©
OPENROUTER_KEYS = [k for k in OPENROUTER_KEYS if k]

# Ø¹Ø¯Ø§Ø¯ Ù„ØªØªØ¨Ø¹ Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø­Ø§Ù„ÙŠ
current_key_index = 0

def get_next_api_key():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ù†Ø¸Ø§Ù… Round-Robin"""
    global current_key_index
    if not OPENROUTER_KEYS:
        raise ValueError("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù…ÙØ§ØªÙŠØ­ API! ØªØ£ÙƒØ¯ Ù…Ù† Ø¥Ø¶Ø§ÙØªÙ‡Ø§ ÙÙŠ Environment Variables")
    key = OPENROUTER_KEYS[current_key_index]
    current_key_index = (current_key_index + 1) % len(OPENROUTER_KEYS)
    return key

# === Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª WordPress ===
WP_DOMAIN = os.getenv("WP_DOMAIN", "https://dalilaleasr.com")
WP_USER = os.getenv("WP_USER", "admin")
WP_APP_PASS = os.getenv("WP_APP_PASS", "")

WP_ENDPOINT = f"{WP_DOMAIN}/wp-json/wp/v2"

# === Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Bing Image Creator (Ø§Ø®ØªÙŠØ§Ø±ÙŠ - Ù„Ù„Ø¶Ø±ÙˆØ±Ø© ÙÙ‚Ø·) ===
BING_COOKIE = os.getenv("BING_COOKIE", "")

# === Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø§Ø¦ÙŠØ© ===
WATERMARK_TEXT = os.getenv("WATERMARK_TEXT", "dalilaleasr.com")
SITE_NAME = "Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¹ØµØ±"

BROWSER_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8",
    "Referer": "https://google.com"
}

# === Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠØ© ===
FREE_TEXT_MODELS = [
    "google/gemini-2.0-flash-exp:free",
    "meta-llama/llama-3.3-70b-instruct:free",
    "deepseek/deepseek-chat:free",
    "qwen/qwen-2.5-72b-instruct:free",
    "meta-llama/llama-3.1-405b-instruct:free",
    "huggingfaceh4/zephyr-7b-beta:free",
]

FREE_VISION_MODELS = [
    "google/gemini-2.0-flash-exp:free",
    "meta-llama/llama-3.2-90b-vision-instruct:free",
    "meta-llama/llama-3.2-11b-vision-instruct:free",
]

# === Ù†Ù…Ø§Ø°Ø¬ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠØ© (Ù„Ù„Ø¶Ø±ÙˆØ±Ø© ÙÙ‚Ø·) ===
FREE_IMAGE_MODELS = [
    "stabilityai/stable-diffusion-xl-base-1.0",
]

# ==========================================
# 1. Ù…ØµØ§Ø¯Ø± RSS Ø§Ù„Ù…ØªÙ†ÙˆØ¹Ø© - ÙƒÙ„ Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª
# ==========================================
RSS_FEEDS = {
    # === Ø§Ù„ÙƒØ±ÙŠØ¨ØªÙˆ ÙˆØ§Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ© ===
    "crypto": [
        "https://cointelegraph.com/rss",
        "https://decrypt.co/feed",
        "https://cryptoslate.com/feed/",
        "https://bitcoinmagazine.com/.rss/full/",
        "https://blockworks.co/feed/",
        "https://u.today/rss",
        "https://cryptonews.com/news/feed/",
        "https://beincrypto.com/feed/",
        "https://dailyhodl.com/feed/",
        "https://zycrypto.com/feed/",
        "https://www.coindesk.com/arc/outboundfeeds/rss/",
        "https://cryptopotato.com/feed/",
        # Ù…ØµØ§Ø¯Ø± Ø¹Ø±Ø¨ÙŠØ© Ù„Ù„ÙƒØ±ÙŠØ¨ØªÙˆ
        "https://ar.cointelegraph.com/rss",
        "https://arabmarketcap.com/feed/",
    ],
    
    # === Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ§Ù„ØªÙ‚Ù†ÙŠØ© ===
    "ai_tech": [
        "https://techcrunch.com/category/artificial-intelligence/feed/",
        "https://www.wired.com/feed/category/ai/latest/rss",
        "https://venturebeat.com/category/ai/feed/",
        "https://www.theverge.com/rss/ai-artificial-intelligence/index.xml",
        "https://openai.com/blog/rss/",
        "https://blog.google/technology/ai/rss/",
        "https://www.technologyreview.com/feed/",
        "https://news.mit.edu/topic/mitartificial-intelligence2-rss.xml",
        "https://ai.googleblog.com/feeds/posts/default",
        "https://machinelearningmastery.com/feed/",
        # Ù…ØµØ§Ø¯Ø± Ø¹Ø±Ø¨ÙŠØ© Ù„Ù„ØªÙ‚Ù†ÙŠØ©
        "https://aitnews.com/feed/",
        "https://www.tech-wd.com/wd/feed/",
        "https://www.arageek.com/feed",
        "https://www.unlimit-tech.com/feed/",
    ],
    
    # === Ø£Ø®Ø¨Ø§Ø± Ø³ÙŠØ§Ø³ÙŠØ© ÙˆØ§Ù‚ØªØµØ§Ø¯ÙŠØ© ===
    "politics_economy": [
        # Ù…ØµØ§Ø¯Ø± Ø¹Ø±Ø¨ÙŠØ©
        "https://www.aljazeera.net/aljazeerarss/a7c186be-1baa-4bd4-9d80-a84db769f779/73d0e1b4-532f-45ef-b135-bba5a9dd06a3",
        "https://www.alarabiya.net/.mrss/ar.xml",
        "https://www.skynewsarabia.com/web/rss",
        "https://arabic.rt.com/rss/",
        "https://www.france24.com/ar/rss",
        "https://www.bbc.com/arabic/index.xml",
        "https://www.independentarabia.com/rss",
        "https://www.aleqt.com/feed.rss",
        "https://makkahnewspaper.com/rss",
        # Ù…ØµØ§Ø¯Ø± Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
        "https://feeds.bbci.co.uk/news/world/rss.xml",
        "https://rss.nytimes.com/services/xml/rss/nyt/World.xml",
        "https://www.reuters.com/rssFeed/worldNews",
        "https://www.theguardian.com/world/rss",
    ],
    
    # === Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ ÙˆØ§Ù„Ø£Ø¹Ù…Ø§Ù„ ===
    "business": [
        "https://www.cnbc.com/id/100003114/device/rss/rss.html",
        "https://www.bloomberg.com/feed/podcast/etf-iq.xml",
        "https://feeds.a]pnews.com/apnews/Business",
        "https://www.ft.com/rss/home",
        "https://www.economist.com/finance-and-economics/rss.xml",
        # Ø¹Ø±Ø¨ÙŠ
        "https://www.argaam.com/ar/feeds/articles-rss",
        "https://www.mubasher.info/rss/news-sa",
        "https://www.aleqt.com/feed.rss",
        "https://arabic.investing.com/rss/news.rss",
    ],
    
    # === Ø´Ø±ÙˆØ­Ø§Øª ÙˆØªÙ‚Ù†ÙŠØ© Ø§Ù„Ø¨Ø±Ø§Ù…Ø¬ ===
    "tutorials": [
        "https://www.howtogeek.com/feed/",
        "https://lifehacker.com/rss",
        "https://www.makeuseof.com/feed/",
        "https://www.digitaltrends.com/feed/",
        "https://www.tomsguide.com/feeds/all",
        "https://www.pcmag.com/feeds/all-articles",
        "https://www.zdnet.com/rss.xml",
        "https://www.cnet.com/rss/all/",
        # Ø¹Ø±Ø¨ÙŠ
        "https://www.arageek.com/tech/feed",
        "https://www.tech-wd.com/wd/feed/",
        "https://www.unlimit-tech.com/feed/",
        "https://me.kaspersky.com/blog/feed/",
    ],
    
    # === Ø£Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ===
    "security": [
        "https://thehackernews.com/feeds/posts/default",
        "https://www.bleepingcomputer.com/feed/",
        "https://krebsonsecurity.com/feed/",
        "https://www.darkreading.com/rss.xml",
        "https://threatpost.com/feed/",
        "https://securityaffairs.co/wordpress/feed",
    ],
    
    # === Ø§Ù„Ø¹Ù„ÙˆÙ… ÙˆØ§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ ===
    "science": [
        "https://www.sciencedaily.com/rss/all.xml",
        "https://www.nature.com/nature.rss",
        "https://www.newscientist.com/feed/home/",
        "https://www.space.com/feeds/all",
        "https://phys.org/rss-feed/",
        # Ø¹Ø±Ø¨ÙŠ
        "https://www.scientificamerican.com/arabic/rss/",
    ],
}

# === Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø³Ø·Ø­Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ===
ALL_FEEDS = []
for category, feeds in RSS_FEEDS.items():
    ALL_FEEDS.extend(feeds)

# ==========================================
# 2. Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø´Ø§Ù…Ù„Ø©
# ==========================================
CATEGORY_MAP = {
    # ÙƒØ±ÙŠØ¨ØªÙˆ
    "News": 2, "Bitcoin": 2, "Ethereum": 2, "Web3": 2, "Regulation": 2, "Crypto": 2,
    "Ø£Ø®Ø¨Ø§Ø±": 2, "Ø¨ÙŠØªÙƒÙˆÙŠÙ†": 2, "Ø¥ÙŠØ«Ø±ÙŠÙˆÙ…": 2, "Ø¹Ù…Ù„Ø§Øª Ø±Ù‚Ù…ÙŠØ©": 2,
    "Market": 3, "Analysis": 3, "Price": 3, "Trading": 3, "Chart": 3,
    "Ø³ÙˆÙ‚": 3, "ØªØ­Ù„ÙŠÙ„": 3, "ØªØ¯Ø§ÙˆÙ„": 3,
    "DeFi": 4, "DEX": 4, "Swap": 4, "Lending": 4, "Ø§Ù„ØªÙ…ÙˆÙŠÙ„ Ø§Ù„Ù„Ø§Ù…Ø±ÙƒØ²ÙŠ": 4,
    "Stablecoin": 6, "USDT": 6, "USDC": 6, "Tether": 6, "Ø¹Ù…Ù„Ø§Øª Ù…Ø³ØªÙ‚Ø±Ø©": 6,
    "DAO": 7, "Governance": 7, "Ø­ÙˆÙƒÙ…Ø©": 7,
    
    # ØªÙ‚Ù†ÙŠØ© ÙˆØ°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
    "AI": 8, "Artificial Intelligence": 8, "Machine Learning": 8, "ChatGPT": 8, "OpenAI": 8,
    "Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ": 8, "ØªØ¹Ù„Ù… Ø¢Ù„ÙŠ": 8,
    "Technology": 9, "Tech": 9, "ØªÙ‚Ù†ÙŠØ©": 9, "ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§": 9,
    "Software": 10, "Apps": 10, "Ø¨Ø±Ø§Ù…Ø¬": 10, "ØªØ·Ø¨ÙŠÙ‚Ø§Øª": 10,
    "Security": 11, "Cybersecurity": 11, "Hacking": 11, "Ø£Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª": 11, "Ø§Ø®ØªØ±Ø§Ù‚": 11,
    
    # Ø³ÙŠØ§Ø³Ø© ÙˆØ§Ù‚ØªØµØ§Ø¯
    "Politics": 12, "Ø³ÙŠØ§Ø³Ø©": 12, "Government": 12, "Ø­ÙƒÙˆÙ…Ø©": 12,
    "Economy": 13, "Ø§Ù‚ØªØµØ§Ø¯": 13, "Business": 13, "Ø£Ø¹Ù…Ø§Ù„": 13,
    "Finance": 14, "Ù…Ø§Ù„ÙŠØ©": 14, "Banking": 14, "Ø¨Ù†ÙˆÙƒ": 14,
    
    # Ø´Ø±ÙˆØ­Ø§Øª
    "Education": 5, "Guide": 5, "Tutorial": 5, "Learn": 5, "How": 5,
    "Ø´Ø±ÙˆØ­Ø§Øª": 5, "Ø¯Ù„ÙŠÙ„": 5, "ØªØ¹Ù„Ù…": 5,
    
    # Ø¹Ù„ÙˆÙ…
    "Science": 15, "Ø¹Ù„ÙˆÙ…": 15, "Space": 15, "ÙØ¶Ø§Ø¡": 15,
    
    "Uncategorized": 1
}
DEFAULT_CATEGORY_ID = 2

# ==========================================
# 3. Ø®Ø±ÙŠØ·Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
# ==========================================
EMERGENCY_MAP = {
    "bitcoin": [
        "https://images.unsplash.com/photo-1621761191319-c6fb62004040?auto=format&fit=crop&w=1280&q=80",
        "https://images.unsplash.com/photo-1596239464385-2800555f68b4?auto=format&fit=crop&w=1280&q=80",
    ],
    "ethereum": [
        "https://images.unsplash.com/photo-1622630998477-20aa696fab05?auto=format&fit=crop&w=1280&q=80",
    ],
    "ai": [
        "https://images.unsplash.com/photo-1677442136019-21780ecad995?auto=format&fit=crop&w=1280&q=80",
        "https://images.unsplash.com/photo-1684391976641-39e8b13c2a81?auto=format&fit=crop&w=1280&q=80",
        "https://images.unsplash.com/photo-1676299081847-824916de030a?auto=format&fit=crop&w=1280&q=80",
    ],
    "tech": [
        "https://images.unsplash.com/photo-1518770660439-4636190af475?auto=format&fit=crop&w=1280&q=80",
        "https://images.unsplash.com/photo-1488590528505-98d2b5aba04b?auto=format&fit=crop&w=1280&q=80",
    ],
    "security": [
        "https://images.unsplash.com/photo-1563986768609-322da13575f3?auto=format&fit=crop&w=1280&q=80",
        "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?auto=format&fit=crop&w=1280&q=80",
    ],
    "economy": [
        "https://images.unsplash.com/photo-1611974789855-9c2a0a7236a3?auto=format&fit=crop&w=1280&q=80",
        "https://images.unsplash.com/photo-1590283603385-17ffb3a7f29f?auto=format&fit=crop&w=1280&q=80",
    ],
    "politics": [
        "https://images.unsplash.com/photo-1529107386315-e1a2ed48a620?auto=format&fit=crop&w=1280&q=80",
        "https://images.unsplash.com/photo-1555848962-6e79363ec58f?auto=format&fit=crop&w=1280&q=80",
    ],
    "science": [
        "https://images.unsplash.com/photo-1507413245164-6160d8298b31?auto=format&fit=crop&w=1280&q=80",
        "https://images.unsplash.com/photo-1451187580459-43490279c0fa?auto=format&fit=crop&w=1280&q=80",
    ],
    "default": [
        "https://images.unsplash.com/photo-1639762681485-074b7f938ba0?auto=format&fit=crop&w=1280&q=80",
        "https://images.unsplash.com/photo-1620321023374-d1a68fddadb3?auto=format&fit=crop&w=1280&q=80",
    ]
}

DB_FILE = "/app/data/history.db" if os.path.exists("/app/data") else "history.db"

# ==========================================
# 4. Ø¯ÙˆØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ==========================================
def init_db():
    os.makedirs(os.path.dirname(DB_FILE), exist_ok=True) if "/" in DB_FILE else None
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS history 
                 (link TEXT PRIMARY KEY, title TEXT, published_at TEXT)''')
    c.execute('''CREATE TABLE IF NOT EXISTS api_usage 
                 (key_index INTEGER PRIMARY KEY, usage_count INTEGER, last_used TEXT)''')
    conn.commit()
    conn.close()

def is_published_link(link):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("SELECT 1 FROM history WHERE link=?", (link,))
    exists = c.fetchone()
    conn.close()
    return exists is not None

def mark_published(link, title):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("INSERT OR IGNORE INTO history VALUES (?, ?, ?)", 
              (link, title, datetime.now().isoformat()))
    conn.commit()
    conn.close()

# ==========================================
# 5. Ù†Ø¸Ø§Ù… Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø±
# ==========================================
def is_duplicate_semantic(new_title):
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("SELECT title FROM history ORDER BY published_at DESC LIMIT 50")
    rows = c.fetchall()
    conn.close()
    if not rows: return False
    
    recent_titles = [row[0] for row in rows if row[0]]
    for existing in recent_titles:
        if SequenceMatcher(None, new_title.lower(), existing.lower()).ratio() > 0.70:
            print(f"   âš ï¸ Ø¹Ù†ÙˆØ§Ù† Ù…ÙƒØ±Ø±: Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ù…Ø¹ '{existing[:30]}...'")
            return True
    return False

# ==========================================
# 6. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
# ==========================================
def check_image_has_watermark(image_url):
    """ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ØµÙˆØ±Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ù„Ø§Ù…Ø© Ù…Ø§Ø¦ÙŠØ©"""
    print(f"   ğŸ” ÙØ­Øµ Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø§Ø¦ÙŠØ©: {image_url[:50]}...")
    
    api_key = get_next_api_key()
    http_client = httpx.Client(verify=False, transport=httpx.HTTPTransport(local_address="0.0.0.0"))
    client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=api_key, http_client=http_client)
    
    for i in range(3):
        model = random.choice(FREE_VISION_MODELS)
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[{
                    "role": "user", 
                    "content": [
                        {
                            "type": "text", 
                            "text": """Analyze this image carefully. Does it contain ANY of the following:
1. Watermarks (text overlay, logo overlay)
2. News channel logos (CNN, BBC, Reuters, etc)
3. Website URLs or domain names
4. Copyright text or symbols
5. Any identifying text overlay

Answer with EXACTLY one of these:
- "CLEAN" if the image has NO watermarks or logos
- "WATERMARK" if the image has ANY watermark, logo, or text overlay"""
                        }, 
                        {"type": "image_url", "image_url": {"url": image_url}}
                    ]
                }],
                max_tokens=50
            )
            result = response.choices[0].message.content.strip().upper()
            print(f"   ğŸ“‹ Ù†ØªÙŠØ¬Ø© Ø§Ù„ÙØ­Øµ: {result}")
            return "WATERMARK" in result
        except Exception as e:
            print(f"   âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙØ­Øµ ({model}): {e}")
            api_key = get_next_api_key()  # Ø¬Ø±Ø¨ Ù…ÙØªØ§Ø­ Ø¢Ø®Ø±
            time.sleep(2)
    
    # ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„ØŒ Ù†ÙØªØ±Ø¶ ÙˆØ¬ÙˆØ¯ Ø¹Ù„Ø§Ù…Ø© Ù…Ø§Ø¦ÙŠØ© Ù„Ù„Ø£Ù…Ø§Ù†
    return True

def apply_watermark_simple(image_bytes):
    """Ø¥Ø¶Ø§ÙØ© Ø¹Ù„Ø§Ù…Ø© Ù…Ø§Ø¦ÙŠØ© Ø¨Ø³ÙŠØ·Ø© Ù„Ù„ØµÙˆØ±Ø© Ø§Ù„Ù†Ø¸ÙŠÙØ©"""
    try:
        img = Image.open(io.BytesIO(image_bytes)).convert("RGBA")
        width, height = img.size
        
        overlay = Image.new("RGBA", img.size, (0, 0, 0, 0))
        draw = ImageDraw.Draw(overlay)
        
        # Ø´Ø±ÙŠØ· Ø´ÙØ§Ù ÙÙŠ Ø§Ù„Ø£Ø³ÙÙ„
        bar_height = int(height * 0.06)
        draw.rectangle([(0, height - bar_height), (width, height)], fill=(0, 0, 0, 140))
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ Ø®Ø· Ø¹Ø±Ø¨ÙŠ Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ
        try:
            font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", int(bar_height * 0.6))
        except:
            try:
                font = ImageFont.truetype("arial.ttf", int(bar_height * 0.6))
            except:
                font = ImageFont.load_default()
        
        # ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø§Ø¦ÙŠØ©
        text = WATERMARK_TEXT
        
        # Ø­Ø³Ø§Ø¨ Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù†Øµ ÙÙŠ Ø§Ù„Ù…Ù†ØªØµÙ
        try:
            bbox = draw.textbbox((0, 0), text, font=font)
            text_width = bbox[2] - bbox[0]
            text_height = bbox[3] - bbox[1]
        except:
            text_width = len(text) * 10
            text_height = bar_height * 0.5
        
        text_x = (width - text_width) / 2
        text_y = height - bar_height + (bar_height - text_height) / 2
        
        # Ø¸Ù„ Ù„Ù„Ù†Øµ
        draw.text((text_x + 2, text_y + 2), text, font=font, fill=(0, 0, 0, 200))
        # Ø§Ù„Ù†Øµ Ø§Ù„Ø£Ø¨ÙŠØ¶
        draw.text((text_x, text_y), text, font=font, fill=(255, 255, 255, 255))
        
        combined = Image.alpha_composite(img, overlay)
        output = io.BytesIO()
        combined.convert("RGB").save(output, format="JPEG", quality=90)
        print(f"   âœ… ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø§Ø¦ÙŠØ©: {WATERMARK_TEXT}")
        return output.getvalue()
        
    except Exception as e:
        print(f"   âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù„Ø§Ù…Ø©: {e}")
        return image_bytes

def apply_watermark_cover(image_bytes):
    """Ø¥Ø®ÙØ§Ø¡ Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø§Ø¦ÙŠØ© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¨Ø´Ø±ÙŠØ· ÙˆÙˆØ¶Ø¹ Ø¹Ù„Ø§Ù…ØªÙ†Ø§ ÙÙˆÙ‚Ù‡"""
    try:
        img = Image.open(io.BytesIO(image_bytes)).convert("RGBA")
        width, height = img.size
        
        overlay = Image.new("RGBA", img.size, (0, 0, 0, 0))
        draw = ImageDraw.Draw(overlay)
        
        # Ø´Ø±ÙŠØ· Ø£ÙƒØ¨Ø± Ù„ØªØºØ·ÙŠØ© Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ù…Ø§Ø¦ÙŠØ© (Ø¹Ø§Ø¯Ø© ÙÙŠ Ø§Ù„Ø£Ø³ÙÙ„ Ø£Ùˆ Ø§Ù„Ø²Ø§ÙˆÙŠØ©)
        bar_height = int(height * 0.12)
        
        # Ø´Ø±ÙŠØ· Ø£Ø³ÙˆØ¯ ØºÙŠØ± Ø´ÙØ§Ù Ù„Ø¥Ø®ÙØ§Ø¡ Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø§Ø¦ÙŠØ© Ø§Ù„Ø£ØµÙ„ÙŠØ©
        draw.rectangle([(0, height - bar_height), (width, height)], fill=(20, 20, 30, 250))
        
        # Ø¥Ø¶Ø§ÙØ© Ø®Ø· Ø²Ø®Ø±ÙÙŠ
        draw.rectangle([(0, height - bar_height), (width, height - bar_height + 3)], fill=(59, 130, 246, 255))
        
        try:
            font_large = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", int(bar_height * 0.5))
            font_small = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", int(bar_height * 0.3))
        except:
            try:
                font_large = ImageFont.truetype("arial.ttf", int(bar_height * 0.5))
                font_small = ImageFont.truetype("arial.ttf", int(bar_height * 0.3))
            except:
                font_large = ImageFont.load_default()
                font_small = font_large
        
        # Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø§Ø¦ÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
        text = WATERMARK_TEXT
        try:
            bbox = draw.textbbox((0, 0), text, font=font_large)
            text_width = bbox[2] - bbox[0]
        except:
            text_width = len(text) * 15
        
        text_x = (width - text_width) / 2
        text_y = height - bar_height + int(bar_height * 0.15)
        
        # Ø¸Ù„ ÙˆÙ†Øµ
        draw.text((text_x + 2, text_y + 2), text, font=font_large, fill=(0, 0, 0, 200))
        draw.text((text_x, text_y), text, font=font_large, fill=(255, 255, 255, 255))
        
        # Ù†Øµ "Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¹ØµØ±" ØªØ­ØªÙ‡
        site_text = SITE_NAME
        try:
            bbox2 = draw.textbbox((0, 0), site_text, font=font_small)
            site_width = bbox2[2] - bbox2[0]
        except:
            site_width = len(site_text) * 8
        
        site_x = (width - site_width) / 2
        site_y = text_y + int(bar_height * 0.45)
        draw.text((site_x, site_y), site_text, font=font_small, fill=(200, 200, 200, 255))
        
        combined = Image.alpha_composite(img, overlay)
        output = io.BytesIO()
        combined.convert("RGB").save(output, format="JPEG", quality=90)
        print(f"   âœ… ØªÙ… Ø¥Ø®ÙØ§Ø¡ Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø§Ø¦ÙŠØ© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© ÙˆÙˆØ¶Ø¹ Ø¹Ù„Ø§Ù…ØªÙ†Ø§: {WATERMARK_TEXT}")
        return output.getvalue()
        
    except Exception as e:
        print(f"   âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØºØ·ÙŠØ© Ø§Ù„Ø¹Ù„Ø§Ù…Ø©: {e}")
        return image_bytes

def get_emergency_image_list(title):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© ØµÙˆØ± Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹"""
    t = title.lower()
    key = "default"
    
    if any(x in t for x in ["bitcoin", "btc", "Ø¨ÙŠØªÙƒÙˆÙŠÙ†"]): key = "bitcoin"
    elif any(x in t for x in ["ethereum", "eth", "Ø¥ÙŠØ«Ø±ÙŠÙˆÙ…"]): key = "ethereum"
    elif any(x in t for x in ["ai", "artificial", "gpt", "Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", "chatgpt"]): key = "ai"
    elif any(x in t for x in ["hack", "security", "Ø£Ù…Ù†", "Ø§Ø®ØªØ±Ø§Ù‚", "cyber"]): key = "security"
    elif any(x in t for x in ["economy", "Ø§Ù‚ØªØµØ§Ø¯", "market", "Ø³ÙˆÙ‚", "stock"]): key = "economy"
    elif any(x in t for x in ["politic", "Ø³ÙŠØ§Ø³", "government", "Ø­ÙƒÙˆÙ…"]): key = "politics"
    elif any(x in t for x in ["science", "Ø¹Ù„Ù…", "space", "ÙØ¶Ø§Ø¡", "research"]): key = "science"
    elif any(x in t for x in ["tech", "ØªÙ‚Ù†", "software", "Ø¨Ø±Ù†Ø§Ù…Ø¬", "app"]): key = "tech"
    
    images = EMERGENCY_MAP.get(key, EMERGENCY_MAP["default"]).copy()
    random.shuffle(images)
    return images

def get_generated_image_url(title):
    """ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ - Ù„Ù„Ø¶Ø±ÙˆØ±Ø© Ø§Ù„Ù‚ØµÙˆÙ‰ ÙÙ‚Ø·"""
    print("   ğŸ¨ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© (Ù„Ù„Ø¶Ø±ÙˆØ±Ø© ÙÙ‚Ø·)...")
    
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Pollinations (Ù…Ø¬Ø§Ù†ÙŠ)
    clean_title = re.sub(r'[^\w\s]', '', title)
    words = clean_title.split()[:6]
    prompt_text = " ".join(words)
    final_prompt = f"{prompt_text}, professional news style, clean, modern, 4k, no text, no watermark"
    encoded_prompt = urllib.parse.quote(final_prompt)
    seed = int(time.time())
    
    return f"https://image.pollinations.ai/prompt/{encoded_prompt}?width=1280&height=720&nologo=true&seed={seed}&model=flux"

# ==========================================
# 7. ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
# ==========================================
def generate_arabic_content(news_item):
    """ØªÙˆÙ„ÙŠØ¯ Ù…Ø­ØªÙˆÙ‰ Ø¹Ø±Ø¨ÙŠ Ø§Ø­ØªØ±Ø§ÙÙŠ Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙˆØ§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª"""
    
    api_key = get_next_api_key()
    print(f"   ğŸ”‘ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙØªØ§Ø­ API: ...{api_key[-8:]}")
    
    http_client = httpx.Client(verify=False, transport=httpx.HTTPTransport(local_address="0.0.0.0"))
    client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=api_key, http_client=http_client)
    
    prompt = f"""Ø£Ù†Øª ÙƒØ§ØªØ¨ Ù…Ø­ØªÙˆÙ‰ Ù…Ø­ØªØ±Ù Ù„Ù…ÙˆÙ‚Ø¹ "Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¹ØµØ±".
Ø§ÙƒØªØ¨ Ù…Ù‚Ø§Ù„Ø§Ù‹ Ø¹Ø±Ø¨ÙŠØ§Ù‹ Ø§Ø­ØªØ±Ø§ÙÙŠØ§Ù‹ Ø§Ø¹ØªÙ…Ø§Ø¯Ø§Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø®Ø¨Ø± Ø§Ù„ØªØ§Ù„ÙŠ ÙÙ‚Ø· (Ø¨Ø¯ÙˆÙ† Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø®Ø§Ø±Ø¬ Ø§Ù„Ù†Øµ).

Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø£ØµÙ„ÙŠ: {news_item['title']}
Ù…Ù„Ø®Øµ Ø§Ù„Ø®Ø¨Ø±: {news_item['summary']}

âš ï¸ Ù‚ÙˆØ§Ø¹Ø¯ ØµØ§Ø±Ù…Ø© Ø¬Ø¯Ø§Ù‹:
1) Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ØŒ Ø£Ø³Ù„ÙˆØ¨ Ø¥Ø®Ø¨Ø§Ø±ÙŠ ÙˆØ§Ø¶Ø­ ÙˆÙ…Ø¨Ø§Ø´Ø±ØŒ Ø¨Ø¯ÙˆÙ† Ù…Ø¨Ø§Ù„ØºØ© Ø£Ùˆ "ÙƒÙ„ÙŠÙƒ Ø¨ÙŠØª".
2) Ù…Ù…Ù†ÙˆØ¹ Ø§Ø®ØªØ±Ø§Ø¹ ØªÙØ§ØµÙŠÙ„. Ø¥Ø°Ø§ Ù„Ù… ØªÙˆØ¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø© ÙÙŠ Ø§Ù„Ø®Ø¨Ø± Ø§ÙƒØªØ¨: "Ø¨Ø­Ø³Ø¨ Ù…Ø§ ÙˆØ±Ø¯ ÙÙŠ Ø§Ù„ØªÙ‚Ø±ÙŠØ±" Ø£Ùˆ ØªØ¬Ø§Ù‡Ù„Ù‡Ø§.
3) Ù„Ø§ ØªØºÙŠÙ‘Ø± Ø£ÙŠ Ø±Ù‚Ù…/Ù†Ø³Ø¨Ø©/ØªØ§Ø±ÙŠØ®/Ø³Ø¹Ø±/Ø§Ø³Ù… Ø¹Ù„Ù…. Ø§ØªØ±ÙƒÙ‡Ø§ ÙƒÙ…Ø§ Ù‡ÙŠ Ø­Ø±ÙÙŠØ§Ù‹.
4) Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¹Ù…Ù„Ø§Øª/Ø§Ù„Ø´Ø±ÙƒØ§Øª/Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ© ØªØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡ÙŠ Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø© (Bitcoin, Ethereum, AI, OpenAI...).
5) Ø·ÙˆÙ„ Ø§Ù„Ù…Ù‚Ø§Ù„: 450 Ø¥Ù„Ù‰ 650 ÙƒÙ„Ù…Ø© ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹.
6) Ø§ÙƒØªØ¨ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨ØµÙŠØºØ© HTML ÙÙ‚Ø· (Ø¨Ø¯ÙˆÙ† MarkdownØŒ Ø¨Ø¯ÙˆÙ† ```ØŒ Ø¨Ø¯ÙˆÙ† Ø¹Ù†Ø§ÙˆÙŠÙ† Ù…Ø«Ù„: Ù…Ù‚Ø¯Ù…Ø©/Ø®Ø§ØªÙ…Ø© ÙƒÙƒÙ„Ù…Ø§Øª Ù…Ù†ÙØµÙ„Ø©).

âœ… Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ (HTML ÙÙ‚Ø·):
A) ØµÙ†Ø¯ÙˆÙ‚ "Ø£Ø¨Ø±Ø² Ø§Ù„Ù†Ù‚Ø§Ø·" (4 Ø¥Ù„Ù‰ 6 Ù†Ù‚Ø§Ø·):
<div style="background:#111827;border-radius:12px;padding:18px;margin-bottom:22px;color:#fff;">
  <h4 style="margin:0 0 12px 0;font-size:1.2em;">ğŸ”¥ Ø£Ø¨Ø±Ø² Ø§Ù„Ù†Ù‚Ø§Ø·</h4>
  <ul style="margin:0;padding-right:18px;line-height:1.8;">
    <li>...</li>
  </ul>
</div>

B) Ø¬Ø³Ù… Ø§Ù„Ù…Ù‚Ø§Ù„:
- Ø§Ø¨Ø¯Ø£ Ø¨Ù…Ù‚Ø¯Ù…Ø© Ù‚ØµÙŠØ±Ø© (2-3 ÙÙ‚Ø±Ø§Øª) Ø¯Ø§Ø®Ù„ <p>.
- Ø«Ù… 3 Ø¥Ù„Ù‰ 5 Ø¹Ù†Ø§ÙˆÙŠÙ† ÙØ±Ø¹ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… <h2>ØŒ ÙˆØªØ­Øª ÙƒÙ„ Ø¹Ù†ÙˆØ§Ù† ÙÙ‚Ø±Ø§Øª <p>.
- Ø§Ø®ØªÙ… Ø¨Ø®Ù„Ø§ØµØ© Ù‚ØµÙŠØ±Ø© Ù…Ù† ÙÙ‚Ø±Ø© ÙˆØ§Ø­Ø¯Ø©.

ğŸ§¾ ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ù…Ù‚Ø§Ù„ (Ø¥Ù„Ø²Ø§Ù…ÙŠ Ø¬Ø¯Ø§Ù‹ ÙˆØ¨Ù†ÙØ³ Ø§Ù„ØµÙŠØºØ© ÙˆØ§Ù„Ø­Ø±ÙˆÙ Ø§Ù„ÙƒØ¨ÙŠØ±Ø© ØªÙ…Ø§Ù…Ø§Ù‹ØŒ ÙˆÙƒÙ„ Ø¹Ù†ØµØ± ÙÙŠ Ø³Ø·Ø± Ù…Ø³ØªÙ‚Ù„):
META_DESC: Ø§ÙƒØªØ¨ ÙˆØµÙØ§Ù‹ Ù…ÙŠØªØ§ Ø¨ÙŠÙ† 150 Ùˆ160 Ø­Ø±ÙØ§Ù‹ (Ø¨Ø¯ÙˆÙ† Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù‚ØªØ¨Ø§Ø³).
TAGS: Ø§ÙƒØªØ¨ 5 Ø¥Ù„Ù‰ 8 ÙˆØ³ÙˆÙ… Ù…ÙØµÙˆÙ„Ø© Ø¨ÙÙˆØ§ØµÙ„ (Ù…Ø²ÙŠØ¬ Ø¹Ø±Ø¨ÙŠ/Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©ØŒ Ø¨Ø¯ÙˆÙ† #).
CATEGORY: Ø§Ø®ØªØ± Ø§Ø³Ù…Ø§Ù‹ ÙˆØ§Ø­Ø¯Ø§Ù‹ ÙÙ‚Ø· Ø­Ø±ÙÙŠØ§Ù‹ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© (Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø´Ø±Ø­ Ø£Ùˆ ÙƒÙ„Ù…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©):
Ø³ÙŠØ§Ø³Ø© | ØµØ­Ø© ÙˆØ·Ø¨ | Ø¨Ø±Ø§Ù…Ø¬ | Ø£Ø¬Ù‡Ø²Ø© | Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ | Ø£Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª | Ø¹Ù…Ù„Ø§Øª Ø±Ù‚Ù…ÙŠØ©

Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹:
- Ù„Ø§ ØªÙƒØªØ¨ Ø£ÙŠ Ù†Øµ Ø¨Ø¹Ø¯ Ø³Ø·Ø± CATEGORY.
- Ù„Ø§ ØªØ¶Ø¹ META_DESC Ø£Ùˆ TAGS Ø£Ùˆ CATEGORY Ø¯Ø§Ø®Ù„ HTML. Ø§ÙƒØªØ¨Ù‡Ø§ ÙƒØ³Ø·ÙˆØ± Ù†ØµÙŠØ© Ø¹Ø§Ø¯ÙŠØ© ÙÙŠ Ø¢Ø®Ø± Ø§Ù„Ù…Ù‚Ø§Ù„.
"""
    
    # Ù…Ø­Ø§ÙˆÙ„Ø© 5 Ù…Ø±Ø§Øª Ù…Ø¹ Ù†Ù…Ø§Ø°Ø¬ Ù…Ø®ØªÙ„ÙØ©
    for attempt in range(5):
        model = random.choice(FREE_TEXT_MODELS)
        try:
            print(f"   ğŸ¤– Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}/5 - Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {model}")
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=2000
            )
            content = response.choices[0].message.content
            content = content.replace("```html", "").replace("```", "").strip()
            content = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', content)
            
            print(f"   âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ù†Ø¬Ø§Ø­ ({len(content)} Ø­Ø±Ù)")
            return content
            
        except Exception as e:
            print(f"   âš ï¸ ÙØ´Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ({model}): {e}")
            api_key = get_next_api_key()  # Ø¬Ø±Ø¨ Ù…ÙØªØ§Ø­ Ø¢Ø®Ø±
            client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=api_key, http_client=http_client)
            time.sleep(3)
    
    return None

def generate_arabic_title(original_title):
    """ØªÙˆÙ„ÙŠØ¯ Ø¹Ù†ÙˆØ§Ù† Ø¹Ø±Ø¨ÙŠ Ø¬Ø°Ø§Ø¨"""
    
    api_key = get_next_api_key()
    http_client = httpx.Client(verify=False, transport=httpx.HTTPTransport(local_address="0.0.0.0"))
    client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=api_key, http_client=http_client)
    
    prompt = f"""Ø­ÙˆÙ‘Ù„ Ù‡Ø°Ø§ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø¥Ù„Ù‰ Ø¹Ù†ÙˆØ§Ù† Ø¹Ø±Ø¨ÙŠ ØµØ­ÙÙŠ Ù…ÙˆØ¬Ø² ÙˆÙˆØ§Ø¶Ø­:

"{original_title}"

Ø´Ø±ÙˆØ· ØµØ§Ø±Ù…Ø©:
1) Ø§Ø­ØªÙØ¸ Ø¨Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙƒÙ…Ø§ Ù‡ÙŠ Ø­Ø±ÙÙŠØ§Ù‹.
2) Ù„Ø§ ØªØªØ±Ø¬Ù… Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¹Ù…Ù„Ø§Øª/Ø§Ù„Ø´Ø±ÙƒØ§Øª/Ø§Ù„Ø£Ø´Ø®Ø§Øµ (Bitcoin, Ethereum, Apple...).
3) Ø¨Ø¯ÙˆÙ† Ù…Ø¨Ø§Ù„ØºØ© Ø£Ùˆ Ø¥Ø«Ø§Ø±Ø© Ø²Ø§Ø¦Ø¯Ø©.
4) Ø§Ù„Ø·ÙˆÙ„ 65 Ø¥Ù„Ù‰ 85 Ø­Ø±ÙØ§Ù‹ ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹.
5) Ø£Ø¹Ø¯ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† Ø£ÙŠ Ø´Ø±Ø­ Ø£Ùˆ Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù‚ØªØ¨Ø§Ø³.
"""
    
    for attempt in range(3):
        model = random.choice(FREE_TEXT_MODELS)
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=100
            )
            title = response.choices[0].message.content.strip()
            title = title.replace('"', '').replace("'", "").strip()
            if title:
                return title
        except Exception as e:
            print(f"   âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: {e}")
            api_key = get_next_api_key()
            client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=api_key, http_client=http_client)
            time.sleep(2)
    
    return original_title  # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø£ØµÙ„ÙŠ ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ÙØ´Ù„

# ==========================================
# 8. Ø§Ù„Ø±ÙØ¹ ÙˆØ§Ù„Ù†Ø´Ø±
# ==========================================
def get_auth_header():
    clean_pass = WP_APP_PASS.replace(' ', '')
    creds = base64.b64encode(f"{WP_USER}:{clean_pass}".encode()).decode()
    return {"Authorization": f"Basic {creds}", "Content-Type": "application/json"}

def get_or_create_tag_id(tag_name):
    try:
        h = get_auth_header()
        r = requests.get(f"{WP_ENDPOINT}/tags?search={urllib.parse.quote(tag_name)}", headers=h, timeout=10)
        if r.status_code == 200 and r.json(): 
            return r.json()[0]['id']
        r = requests.post(f"{WP_ENDPOINT}/tags", headers=h, json={"name": tag_name}, timeout=10)
        if r.status_code == 201: 
            return r.json()['id']
    except Exception as e:
        print(f"   âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙˆØ³Ù… '{tag_name}': {e}")
    return None

def upload_image_with_seo(img_url, alt_text, has_watermark=False):
    """Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø§Ø¦ÙŠØ©"""
    print(f"   â¬†ï¸ Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±Ø©: {alt_text[:30]}...")
    try:
        r_img = requests.get(img_url, headers=BROWSER_HEADERS, timeout=30, verify=False)
        if r_img.status_code == 200:
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø§Ø¦ÙŠØ©
            if has_watermark:
                final_image_data = apply_watermark_cover(r_img.content)
            else:
                final_image_data = apply_watermark_simple(r_img.content)
            
            filename = f"dalilaleasr_{int(time.time())}.jpg"
            headers_wp = get_auth_header()
            headers_wp["Content-Disposition"] = f"attachment; filename={filename}"
            headers_wp["Content-Type"] = "image/jpeg"
            
            r_wp = requests.post(f"{WP_ENDPOINT}/media", headers=headers_wp, data=final_image_data, timeout=60)
            if r_wp.status_code == 201: 
                media_id = r_wp.json()['id']
                
                # ØªØ­Ø¯ÙŠØ« SEO Ù„Ù„ØµÙˆØ±Ø©
                seo_data = {
                    "alt_text": alt_text, 
                    "title": alt_text, 
                    "caption": f"Ø§Ù„Ù…ØµØ¯Ø±: Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¹ØµØ± - {alt_text}", 
                    "description": alt_text
                }
                requests.post(f"{WP_ENDPOINT}/media/{media_id}", headers=get_auth_header(), json=seo_data, timeout=10)
                print("   âœ… ØªÙ… Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ù†Ø¬Ø§Ø­")
                return media_id
            else:
                print(f"   âŒ ÙØ´Ù„ Ø§Ù„Ø±ÙØ¹: {r_wp.status_code}")
    except Exception as e:
        print(f"   âŒ Ø®Ø·Ø£ ÙÙŠ Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±Ø©: {e}")
    return None

def publish_to_wp(title, content, feat_img_id):
    """Ù†Ø´Ø± Ø§Ù„Ù…Ù‚Ø§Ù„ ÙÙŠ WordPress"""
    meta_desc, tags, cat_id = "", [], DEFAULT_CATEGORY_ID
    def _pick_best_category_id(category_text: str) -> int:
        """Ø§Ø®ØªØ± Ø£Ù‚Ø±Ø¨ ØªØµÙ†ÙŠÙ Ù…Ø¹Ø±ÙˆÙ Ù…Ù† CATEGORY_MAP Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†Øµ CATEGORY Ø§Ù„Ù‚Ø§Ø¯Ù… Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬."""
        if not category_text:
            return DEFAULT_CATEGORY_ID

        # Ø®Ø° Ø£ÙˆÙ„ Ø³Ø·Ø± ÙÙ‚Ø· (ØªØ¬Ù†Ø¨ Ø£ÙŠ Ø´Ø±Ø­ Ø¥Ø¶Ø§ÙÙŠ)
        category_text = category_text.strip().splitlines()[0].strip()

        # Ø¥Ø°Ø§ Ø¬Ø§Ø¡ Ø¨ØµÙŠØºØ©: "X | Y | Z" Ø§Ø®ØªØ± Ø£ÙˆÙ„ Ø¹Ù†ØµØ± Ù…Ø¹Ø±ÙˆÙ
        if "|" in category_text:
            parts = [p.strip() for p in category_text.split("|") if p.strip()]
            for p in parts:
                if p in CATEGORY_MAP:
                    return CATEGORY_MAP[p]
            category_text = parts[0] if parts else category_text

        # Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø¨Ø§Ø´Ø±Ø©
        if category_text in CATEGORY_MAP:
            return CATEGORY_MAP[category_text]

        # Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¬Ø²Ø¦ÙŠØ© (contains)
        low = category_text.lower()
        for k, v in CATEGORY_MAP.items():
            if k.lower() in low or low in k.lower():
                return v

        # Ù…Ø·Ø§Ø¨Ù‚Ø© ØªÙ‚Ø±ÙŠØ¨ÙŠØ© (fuzzy)
        best_k, best_ratio = None, 0.0
        for k in CATEGORY_MAP.keys():
            r = difflib.SequenceMatcher(None, low, k.lower()).ratio()
            if r > best_ratio:
                best_ratio, best_k = r, k

        if best_k and best_ratio >= 0.60:
            return CATEGORY_MAP[best_k]

        return DEFAULT_CATEGORY_ID

    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØªØ§ ÙˆØ§Ù„ÙˆØ³ÙˆÙ… ÙˆØ§Ù„ØªØµÙ†ÙŠÙ
    if "META_DESC:" in content:
        try:
            parts = content.split("META_DESC:")
            content = parts[0]
            rest = parts[1]
            if "TAGS:" in rest:
                t_parts = rest.split("TAGS:")
                meta_desc = t_parts[0].strip()
                rest = t_parts[1]
                if "CATEGORY:" in rest:
                    c_parts = rest.split("CATEGORY:")
                    tags = [t.strip() for t in c_parts[0].split(',') if t.strip()]
                    
                    cat_id = _pick_best_category_id(c_parts[1])
        except Exception as e:
            print(f"   âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙŠØªØ§: {e}")
    
    tag_ids = [tid for t in tags if t and (tid := get_or_create_tag_id(t))]
    focus_keyword = tags[0] if tags else "Ø£Ø®Ø¨Ø§Ø±"
    
    data = {
        "title": title, 
        "content": content, 
        "status": "publish",
        "categories": [cat_id], 
        "tags": tag_ids, 
        "excerpt": meta_desc,
        "featured_media": feat_img_id,
        "meta": { 
            "rank_math_focus_keyword": focus_keyword,
            "rank_math_description": meta_desc
        }
    }
    
    try:
        r = requests.post(f"{WP_ENDPOINT}/posts", headers=get_auth_header(), json=data, timeout=30)
        if r.status_code == 201: 
            return r.json()['link']
        print(f"   âŒ ÙØ´Ù„ Ø§Ù„Ù†Ø´Ø±: {r.status_code} - {r.text[:200]}")
    except Exception as e:
        print(f"   âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù†Ø´Ø±: {e}")
    return None

def extract_image_from_entry(entry):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† Ù…Ø¯Ø®Ù„ RSS"""
    # media_content
    if hasattr(entry, 'media_content') and entry.media_content:
        try:
            return entry.media_content[0].get('url') if isinstance(entry.media_content[0], dict) else entry.media_content[0]['url']
        except: pass
    
    # media_thumbnail
    if hasattr(entry, 'media_thumbnail') and entry.media_thumbnail:
        try:
            return entry.media_thumbnail[0].get('url')
        except: pass
    
    # enclosures
    if hasattr(entry, 'enclosures') and entry.enclosures:
        for enc in entry.enclosures:
            if 'image' in enc.get('type', ''):
                return enc.get('href') or enc.get('url')
    
    # links
    if hasattr(entry, 'links') and entry.links:
        for l in entry.links:
            link_type = getattr(l, 'type', '') or l.get('type', '')
            if 'image' in str(link_type): 
                return getattr(l, 'href', None) or l.get('href')
    
    # Ù…Ù† Ø§Ù„Ù…Ù„Ø®Øµ
    if hasattr(entry, 'summary') and entry.summary:
        m = re.search(r'<img.*?src=["\']([^"\']+)["\']', entry.summary)
        if m: return m.group(1)
    
    # Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰
    if hasattr(entry, 'content') and entry.content:
        for c in entry.content:
            content_value = getattr(c, 'value', '') or ''
            m = re.search(r'<img.*?src=["\']([^"\']+)["\']', content_value)
            if m: return m.group(1)
    
    return None

# ==========================================
# 9. Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
# ==========================================
def process_single_entry(entry):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø¨Ø± ÙˆØ§Ø­Ø¯"""
    print(f"\n   âš¡ Ù…Ø¹Ø§Ù„Ø¬Ø©: {entry.title[:60]}...")
    
    # 1. ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©
    arabic_title = generate_arabic_title(entry.title)
    print(f"   ğŸ“ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø¹Ø±Ø¨ÙŠ: {arabic_title[:50]}...")
    
    # 2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† Ø§Ù„Ù…ØµØ¯Ø±
    original_img = extract_image_from_entry(entry)
    final_img_url = None
    has_watermark = False
    
    if original_img:
        print(f"   ğŸ–¼ï¸ ØµÙˆØ±Ø© Ù…Ù† Ø§Ù„Ù…ØµØ¯Ø±: {original_img[:50]}...")
        has_watermark = check_image_has_watermark(original_img)
        final_img_url = original_img
    else:
        # Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙˆØ±Ø© - Ø§Ø³ØªØ®Ø¯Ø§Ù… ØµÙˆØ±Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
        print("   âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙˆØ±Ø© - Ø§Ø³ØªØ®Ø¯Ø§Ù… ØµÙˆØ±Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©...")
        emergency_images = get_emergency_image_list(entry.title)
        if emergency_images:
            final_img_url = emergency_images[0]
            has_watermark = False
    
    # 3. Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±Ø©
    fid = None
    if final_img_url:
        fid = upload_image_with_seo(final_img_url, arabic_title, has_watermark)
    
    # Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„Ø±ÙØ¹ØŒ Ø¬Ø±Ø¨ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
    if not fid:
        print("   ğŸ”„ Ù…Ø­Ø§ÙˆÙ„Ø© ØµÙˆØ± Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©...")
        for backup_url in get_emergency_image_list(entry.title):
            fid = upload_image_with_seo(backup_url, arabic_title, False)
            if fid: break
    
    if not fid:
        print("   âŒ ÙØ´Ù„ Ø±ÙØ¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙˆØ±")
        return False
    
    # 4. ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠ
    summary = getattr(entry, 'summary', '') or getattr(entry, 'description', '')
    content = generate_arabic_content({
        'title': entry.title, 
        'summary': summary
    })
    
    if not content:
        print("   âŒ ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰")
        return False
    
    # 5. Ø§Ù„Ù†Ø´Ø±
    link = publish_to_wp(arabic_title, content, fid)
    if link:
        print(f"   âœ… ØªÙ… Ø§Ù„Ù†Ø´Ø±: {link}")
        mark_published(entry.link, arabic_title)
        return True
    
    return False

def main():
    print("=" * 60)
    print("ğŸš€ Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¹ØµØ± - Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ø´Ø± Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ V1.0")
    print("=" * 60)
    print(f"   ğŸŒ Ø§Ù„Ù…ÙˆÙ‚Ø¹: {WP_DOMAIN}")
    print(f"   ğŸ‘¤ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {WP_USER}")
    print(f"   ğŸ”‘ Ø¹Ø¯Ø¯ Ù…ÙØ§ØªÙŠØ­ API: {len(OPENROUTER_KEYS)}")
    print(f"   ğŸ“° Ø¹Ø¯Ø¯ Ù…ØµØ§Ø¯Ø± RSS: {len(ALL_FEEDS)}")
    print(f"   ğŸ’§ Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ù…Ø§Ø¦ÙŠØ©: {WATERMARK_TEXT}")
    print("=" * 60)
    
    if not OPENROUTER_KEYS:
        print("âŒ Ø®Ø·Ø£: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙØ§ØªÙŠØ­ API!")
        print("   ØªØ£ÙƒØ¯ Ù…Ù† Ø¥Ø¶Ø§ÙØ© OPENROUTER_KEY_1 Ø¥Ù„Ù‰ OPENROUTER_KEY_6 ÙÙŠ Environment Variables")
        return
    
    init_db()
    
    articles_per_cycle = 0
    max_articles_per_cycle = 10  # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ù…Ù‚Ø§Ù„Ø§Øª ÙÙŠ ÙƒÙ„ Ø¯ÙˆØ±Ø©
    
    while True:
        print(f"\n{'='*60}")
        print(f"â° Ø¯ÙˆØ±Ø© Ø¬Ø¯ÙŠØ¯Ø©: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
        print(f"{'='*60}")
        
        articles_per_cycle = 0
        random.shuffle(ALL_FEEDS)  # Ø®Ù„Ø· Ø§Ù„Ù…ØµØ§Ø¯Ø±
        
        for feed_url in ALL_FEEDS:
            if articles_per_cycle >= max_articles_per_cycle:
                print(f"\n   ğŸ›‘ ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ ({max_articles_per_cycle} Ù…Ù‚Ø§Ù„)")
                break
            
            try:
                print(f"\nğŸ“¡ Ù‚Ø±Ø§Ø¡Ø©: {feed_url[:50]}...")
                d = feedparser.parse(feed_url)
                
                if not d.entries:
                    continue
                
                for entry in d.entries[:3]:  # Ø£ÙˆÙ„ 3 Ø£Ø®Ø¨Ø§Ø± Ù…Ù† ÙƒÙ„ Ù…ØµØ¯Ø±
                    if articles_per_cycle >= max_articles_per_cycle:
                        break
                    
                    # ØªØ®Ø·ÙŠ Ø§Ù„Ù…Ù†Ø´ÙˆØ± Ø³Ø§Ø¨Ù‚Ø§Ù‹
                    if is_published_link(entry.link):
                        continue
                    
                    # ØªØ®Ø·ÙŠ Ø§Ù„Ù…ÙƒØ±Ø± Ø¯Ù„Ø§Ù„ÙŠØ§Ù‹
                    if is_duplicate_semantic(entry.title):
                        continue
                    
                    # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆÙ†Ø´Ø±
                    if process_single_entry(entry):
                        articles_per_cycle += 1
                    
                    # Ø§Ù†ØªØ¸Ø§Ø± Ø¨ÙŠÙ† Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª
                    time.sleep(20)
                    
            except Exception as e:
                print(f"   âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…ØµØ¯Ø±: {e}")
                continue
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„Ø¯ÙˆØ±Ø©: ØªÙ… Ù†Ø´Ø± {articles_per_cycle} Ù…Ù‚Ø§Ù„")
        print(f"ğŸ’¤ Ø§Ø³ØªØ±Ø§Ø­Ø© 20 Ø¯Ù‚ÙŠÙ‚Ø©...")
        print(f"{'='*60}")
        
        time.sleep(1200)  # 20 Ø¯Ù‚ÙŠÙ‚Ø©

if __name__ == "__main__":
    main()
